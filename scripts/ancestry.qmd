---
output: html_document
execute: 
  freeze: auto
editor_options: 
  chunk_output_type: console
---
# Genetic Ancestry {.unnumbered}

Genetic ancestry plays a pivotal role in genome-wide association studies (GWAS), providing insights into the population-specific genetic variations that may contribute to disease phenotypes. Accurate assessment of ancestry allows for the control of population stratification, which can confound results if not properly accounted for. Principal Component Analysis (PCA) is commonly used to visualize and correct for ancestry-related differences by identifying axes of genetic variation. Additionally, understanding admixture improves our interpretation of genetic data, enabling more precise localization of disease-associated variants in diverse populations.

## Prinicpal Component Analysis 

PLINK enables us to conduct Principal Component Analysis (PCA) on genetic data. In this case, we have merged the HABS-HD dataset with the 1000 Genomes (1KG) dataset to initially derive principal components from the 1KG, which are then used to project the genetic data of the HABS-HD dataset onto. This will generate two files `work/imputed_1kG_merged.eigenvec` - the eigenvectors - and `work/imputed_1kG_merged.eigenval` the PCs. 

```{bash}
#| eval: false
#| label: plink_pca
#| code-summary: PLINK PCA
#| code-fold: FALSE

plink \
    --keep-allele-order \
    --bfile resources/genetic_epi/imputed_1kG_merged \
    --fam resources/genetic_epi/imputed_1kG_merged_fixed.fam \
    --pca 10 \
    --within resources/genetic_epi/1kG_pops.txt \
    --pca-clusters resources/genetic_epi/1kG_pops_unique.txt \
    --out work/imputed_1kG_merged
```

To categorize HABS-HD samples into the closest 1KG superpopulation, we calculate the geometric median for each cluster, assess the Euclidean distance from each sample to these medians, and assign samples to the nearest cluster accordingly.

```{r}
#| eval: false
#| label: Import Packages
#| code-summary: Import Packges
#| code-fold: TRUE

#!/usr/bin/env Rscript

message("Loading packages")

suppressPackageStartupMessages(library(dplyr))
library(readr)
library(magrittr)
suppressPackageStartupMessages(library(tidyr))
library(stringr)
library(tibble)
suppressPackageStartupMessages(library(purrr))
library(ggplot)

# Get geometric median
## rdocumentation.org/packages/bigutilsr/versions/0.3.3/topics/geometric_median

geometric_median <- function(u, tol = 1e-10, maxiter = 1000, by_grp = NULL) {
  if (!is.null(by_grp))
    return(do.call("rbind", by(u, by_grp, geometric_median)))
  u_old <- colMeans(u)
  for (k in seq_len(maxiter)) {
    norm <- sqrt(rowSums(sweep(u, 2, u_old, "-")^2))
    u_new <- colSums(sweep(u, 1, norm, "/")) / sum(1 / norm)
    diff <- max(abs(u_new - u_old))
    if (diff < tol)
      break
    u_old <- u_new
  }
  if (k == maxiter)
    warning("The maximum number of iterations has been reached.")
  u_new
}

# assign sample to cluster
## https://www.biorxiv.org/content/10.1101/2020.10.06.328203v2.full
## adomingues.github.io/2015/09/24/finding-closest-element-to-a-number-in-a-list

find_cluster <- function(df, clusters) {
  superpops <- clusters$superpop
  samp_pcs <- select(df, starts_with("PC"))
  mat <- bind_rows(clusters, samp_pcs) %>% {suppressWarnings(dist(.))}
  # mat
  clus <- which.min(as.matrix(mat)[6, 1:5])
  dplyr::mutate(df, superpop_infered = superpops[clus])
}
```

You will need to ensure the following files are in your `resources` and `work` directories. 

```{r}
#| eval: false
#| label: Import Data
#| code-summary: Import Data
#| code-fold: TRUE

vec <- 'work/imputed_1kG_merged.eigenvec'
val <- 'work/imputed_1kG_merged.eigenval'
base <- 'resources/genetic_epi/1kG_pops.txt'
target <- 'work/habshd_sampleQC.fam'
# output <- snakemake@output[["excl"]]
# rmd <- snakemake@output[["rmd"]]
sample <- 'HABS-HD'
population <- 'all'
# extraref <- snakemake@params[["extraref"]]
# sdev <- snakemake@params[["sd"]]
pcs_out_path <- 'work/habs_pca.tsv'
tg_pops_file <- 'resources/genetic_epi/tg_subpops.tsv'


#load("output/ADGC/x_present_AA/ADC8-AA_exclude.pca.params.Rdata")

if (tolower(population) == "all") {
  all_pops <- T
} else {
  all_pops <- F
}

##---- Read in Data ----##
message("Reading data files")

# count columns and PCs
n_eig <- count_fields(vec, tokenizer_delim(delim = " "), n_max = 1) - 2

# Generate colnames
pc_names <- paste0("PC", 1:n_eig)
names_col <- c("FID", "IID", pc_names)

# Read in eigenvectors and z-score transform
pca_orig <- read_delim(vec,
                  delim = " ", col_names = names_col,
                  col_types = cols(.default = "d", FID = "c", IID = "c")) %>%
         mutate_at(pc_names, function(x) as.vector(scale(x)))

# read in egienvalues
eigenval <- val %>%
  read_lines %>%
  parse_number %>%
  tibble(eigenval = .,
         PC = factor(pc_names, levels = pc_names)) %>% #PC Names
  mutate(PVE = round(eigenval / sum(eigenval), 3)) %>% #PVE
  select(PC, eigenval, PVE) #Reorder columns

# population data file, usually from 1000 genomes and potentially with extra ref
base_pops_raw <- read_table(base, col_types = cols(.default = "c"))

# population data from target set
famcols <- c("FID", "IID", "PID", "MID", "Sex", "Pheno")
target_pops_raw <- read_table(target, col_names = famcols,
  col_types = "ccccii")

message("Processing data")
# ---- Data wrangling ---- #

# Read in populations and superpops
tg_pops <- read_tsv(tg_pops_file, col_types = "cccc")
populations <- tg_pops %>% select(pop, spop) %>% deframe %>% as.list
superpops <- unlist(populations) %>% unique()

extra_pops <- base_pops_raw[
    !(base_pops_raw$Population %in% names(populations)), ] %>%
  distinct(Population) %>%
  pull(Population)

if (length(extra_pops) == 1 && extraref == extra_pops) {
  populations[extraref] <- population
} else if (length(extra_pops) == 0 && extraref != "none") {
  stop("Extra population missing from reference!")
} else if (length(extra_pops) > 1) {
  stop("Non-1kG population codes are not yet implemented. Go bug Brian.")
}

# Deal with invalid cohort names

if (sample %in% names(populations)) {
  sample <- paste0("s_", sample)
}

if (sample %in% populations) {
  sample_s <- paste0("s_", sample)
} else {
  sample_s <- sample
}


##  Munge population dataframes from 1000 genomes
base_pops <- base_pops_raw %>%
  mutate(cohort = "Reference",
         superpop = recode(.$Population, !!!populations))

##  Munge target population dataframes
target_pops <- target_pops_raw %>%
  select(FID, IID) %>%
  mutate(Population = sample, superpop = sample_s,
    cohort = sample_s)

## Check this
remove_tg <- TRUE
if (remove_tg) {
  target_pops <- target_pops %>%
    filter(!(IID %in% base_pops$IID & FID %in% base_pops$FID))
}

# fix improperly split FID_IID
pca_fidiid <- pca_orig %>%
  unite("FIDIID", FID, IID, sep = "_")


##  Munge PCA, base pop and target pop
both_pops <- target_pops %>%
  bind_rows(base_pops) %>%
  ##### FIX BAD FID_IID SPLIT #####
  unite("FIDIID", FID, IID, sep = "_", remove = F)

pca_corrected <- pca_fidiid %>%
  left_join(both_pops, by = "FIDIID") %>%
  select(any_of(names(both_pops)), everything(), -FIDIID) %>%
  mutate(FID = str_remove(FID, "^1000g___"))

## Colours for plots
pca_col <- pca_corrected %>%
  count(superpop) %>%
  mutate(color = ifelse(superpop == sample_s, "black", NA)) %>%
  mutate(color = ifelse(superpop == "AFR", "#E69F00", color)) %>%
  mutate(color = ifelse(superpop == "AMR", "#0072B2", color)) %>%
  mutate(color = ifelse(superpop == "EAS", "#009E73", color)) %>%
  mutate(color = ifelse(superpop == "EUR", "#CC79A7", color)) %>%
  mutate(color = ifelse(superpop == "NFE", "#CC79A7", color)) %>%
  mutate(color = ifelse(superpop == "FIN", "#960018", color)) %>%
  mutate(color = ifelse(superpop == "SAS", "#D55E00", color)) %>%
  mutate(color = ifelse(superpop == "MID", "#56B4E9", color)) %>%
  mutate(color = ifelse(superpop == "AMI", "#F0E442", color)) %>%
  add_row(
    superpop = c("Black", "Hispanic", "NHW"), 
    n = 0, 
    color = c("#E69F00", "#0072B2", "#CC79A7")
  )


# Pull out 1000 genomes samples
kg <- filter(pca_corrected, cohort == "Reference")

# find geometric median of each PC for each cluster
clusters <-
  select(kg, starts_with("PC")) %>%
  geometric_median(by_grp = kg$superpop) %>%
  as_tibble(rownames = "superpop")

# extract sample information and assign to cluster
pca <- pca_corrected %>%
  group_split(IID) %>%
  map_df(find_cluster, clusters)

# Export PCA 
write_tsv(pca, pcs_out_path)


```

Now we can visualize the PCA to see how HABS-HD clusters with 1KG

```{r}
#| eval: false
#| label: 1KG PCA
#| code-summary: Visualize 1KG + HABS-HD
#| code-fold: TRUE

color_vector <- setNames(pca_col$color, pca_col$superpop)

# PC1 x PC2
ga_pc1 <- ggplot() +  
  geom_point(data = filter(pca, cohort == 'Reference'), 
             aes(x = PC1, y = PC2, color = superpop), shape = 15, size = 2) + 
  geom_point(data = filter(pca, cohort == 'HABS-HD'), 
             aes(x = PC1, y = PC2, color = superpop), size = 0.75) + 
  scale_color_manual(values = color_vector) + 
  theme_bw()

# PC3 x PC4
ga_pc3 <- ggplot() +  
  geom_point(data = filter(pca, cohort == 'Reference'), 
             aes(x = PC3, y = PC4, color = superpop), shape = 15, size = 2) + 
  geom_point(data = filter(pca, cohort == 'HABS-HD'), 
             aes(x = PC3, y = PC4, color = superpop), size = 0.75) + 
  scale_color_manual(values = color_vector) + 
  theme_bw()

cowplot::plot_grid(
  ga_pc1, ga_pc3, 
)

```

Lets join with the phenotype data to compare ancestry and race

```{r}
#| eval: false
#| label: Visualize HABS-HD
#| code-summary: Visualize HABS-HD
#| code-fold: TRUE

pca_pheno <- pca %>% 
  filter(cohort == "HABS-HD") %>%
  mutate(IID = as.numeric(IID)) %>%
  left_join(read_csv('work/habshd_pheno.csv'), by = c('IID' = 'med_id'))

# PC1 x PC2
habshd_ga <- ggplot(pca_pheno, aes(x = PC1, y = PC2, color = superpop_infered)) +  
  geom_point() + 
  scale_color_manual(values = color_vector) + 
  theme_bw() + 
  labs(title = "Genetic Ancestry")

# PC1 x PC2
habshd_race <- ggplot(pca_pheno, aes(x = PC1, y = PC2, color = race)) +  
  geom_point() + 
  scale_color_manual(values = color_vector) + 
  theme_bw() + 
  labs(title = "Race")

cowplot::plot_grid(
  habshd_ga, habshd_race
)

```

## ADMIXTURE 

### Reference Processing

To prepare the gnomAD reference, we did the following:

*  Remove samples without a population inference from gnomAD or without high_quality set to TRUE.
*  Make a column (`spop`) by doing the following with the populations inferred by gnomAD:
   *  Merge "nfe" and "fin" into "EUR"
   *  Move oceanic subjects from "oth" to their own "OCE" category.
   *  Capitalize all other superpopulations.
*  Make a column (`spop_checked`) where the original superpopulations match the inferred superpopulations:
   *  The new `spop` column is used for inferred superpopulation.
   *  The `genetic_region` column is used for original superpopulation.
   *  "CSA" in `genetic_region` is considered a match to "SAS" in `spop`. "SAS" is used in the new column. 
   *  All subjects where there is no match are set to "NA"

### ADMIXTURE Procedure

The following steps are used to generate Global Ancestry Inference (GAI) estimates:

1. Process the reference label data as described above.
2. Obtain the intersection of the reference and target varients, then prune the reference with a 100kb window and R^2 of 0.1.
3. Restrict sample genotypes to those present in the pruned reference, then merge with the reference samples. Check that the `.bim` files are identical.
4. Run unsupervised ADMIXTURE with K = 12 on the reference dataset.
5. Run ADMIXTURE projection on the merged reference and target samples.
6. Read in the processed reference labels, ADMIXTURE cluster estimates (Q files), and PLINK `.fam` files.
7. Merge the reference labels with the ADMIXTURE cluster estimates and extract the reference samples for labeling, excluding Middle Eastern reference samples.
8. Label the clusters by assigning to each cluster the superpopulation with the highest average proportion within that cluster. The checked superpopulation labels are used for this labeling process.
9. Using the cluster labels, calculate GAI proportions and maximum superpopulation for all samples.
10. Visualize below.

We can execute ADMIXTURE using the code below; however, it requires approximately 24 hours of compute time. We have determined that K=12 is the optimal number of ancestral populations for 1KG + HGDP datasets. Our goal is to project the HABS-HD samples onto this reference dataset. This will produce `.Q` and `.P` file that contain the estimated ancestry fractions for each individual across the inferred populations and the allele frequencies for each population respectivly.

```{bash}
#| eval: false
#| label: ADMIXTURE Projection
admixture -P -s 42 habshd_merged_gnomad-hgdp-1kg.hg38.bed 12 -j1

```

Lets visualize the global ancestry of the HABS-HD dataset. Make sure the following files are in your `work` directory. 

- `work/gnomad-hgdp-1kg_pruned_habshd.hg38.fam`
- `work/habshd_merged_gnomad-hgdp-1kg.hg38.12.Q`
- `work/habshd_merged_gnomad-hgdp-1kg.hg38.fam`
- `work/hgdp_1kg.popdata.tsv.gz`

```{r}
#| eval: false
#| label: Import ADMIXTURE Packages
#| code-summary: ADMIXTURE Packages
#| code-fold: TRUE

suppressPackageStartupMessages(library(dplyr))
library(readr)
library(tidyr)
library(purrr)
library(tibble)
library(stringr)
```


```{r}
#| eval: false
#| label: Import ADMIXTURE
#| code-summary: Import ADMIXTURE
#| code-fold: TRUE

## Input and output files
in_fam_ref <- 'work/gnomad-hgdp-1kg_pruned_habshd.hg38.fam'
in_q_samp <- 'work/habshd_merged_gnomad-hgdp-1kg.hg38.12.Q'
in_fam_samp <- 'work/habshd_merged_gnomad-hgdp-1kg.hg38.fam'
in_pops <- 'work/hgdp_1kg.popdata.tsv.gz'
out_anc <- 'work/admixture_cohort-habshd_ref-gnomad-hgdp-1kg.hg38.tsv'

# Fam and popfiles
## ======================================##
message("Reading pop file \n")
pops <- in_pops |>
  read_tsv(col_types = cols(.default = "c")) |>
  rename(ID = IID)

message("Reading fam files \n")
read_fam <- function(in_fam) {
  in_fam |>
    read_table(col_names = c("ID"), col_types = "-c----") |>
    mutate(order = row_number())
}

famfile_ref <- read_fam(in_fam_ref) |>
  mutate(partition = "reference")
famfile_samp <- read_fam(in_fam_samp) |>
  mutate(partition = "sample")

famfile <- bind_rows(famfile_ref, famfile_samp)

# Interpreting unsupervised admixture output #
## ======================================##
message("Reading unsupervised admixture output \n")

read_q <- function(in_q, fam) {
  in_q |>
    read_table(col_names = FALSE, col_types = cols(.default = "d")) |>
    bind_cols(fam) |>
    rename_with(~ str_replace(.x, "^X", "k"))
}

tbl_admix_samp <- read_q(in_q_samp, famfile_samp)

overlap <- intersect(famfile_ref$ID, tbl_admix_samp$ID)
if (length(overlap) == nrow(famfile_ref)) {
  tbl_admix <- tbl_admix_samp |>
    left_join(pops, by = "ID") |>
    mutate(partition = ifelse(ID %in% famfile_ref$ID, "reference", partition))
  tbl_admix_ref <- tbl_admix |>
    filter(ID %in% famfile_ref$ID) |>
    mutate(FID = "reference")
  tbl_admix_samp <- tbl_admix |>
    filter(!(ID %in% tbl_admix_ref$ID))
} else if (length(overlap) != 0) {
  stop("Missing reference samples")
} else {
  tbl_admix_ref <- read_q(in_q_ref, famfile_ref)
  tbl_admix_ref <- tbl_admix_ref |>
    left_join(pops, by = "ID") |>
    mutate(FID = "reference")
  tbl_admix <- bind_rows(tbl_admix_ref, tbl_admix_samp)
}

# Determining cluster labels

cluster_cols <- names(tbl_admix)[str_detect(names(tbl_admix), "^k\\d+$")]

assign_labels <- function(tbl_admix) {
  if ("spop_checked" %in% colnames(tbl_admix)) {
    assign_admix_raw <- tbl_admix |>
      select(any_of(c("FID", "IID", "ID")),
        spop = spop_checked, matches("^k\\d+$")) |>
      filter(spop != "MID") |> # remove middle eastern from assignment
      group_by(spop) |>
      summarise(across(where(is.numeric), mean)) |>
      filter(!is.na(spop))
  } else {
    assign_admix_raw <- tbl_admix |>
      group_by(spop) |>
      summarise(across(where(is.numeric), mean)) |>
      filter(!is.na(spop))
  }

  assign_admix_mat <- assign_admix_raw |>
    column_to_rownames(var = "spop") |>
    as.matrix()

  assign_admix <- assign_admix_mat |>
    t() |>
    as.data.frame() |>
    (\(.) mutate(., anc = colnames(.)[apply(., 1, which.max)]))() |>
    as_tibble(rownames = "cluster") |>
    rowwise() |>
    mutate(maxval = max(c_across(where(is.numeric)))) |>
    group_by(anc) |>
    arrange(-maxval) |>
    mutate(n = n(),
           cname = ifelse(n > 1, paste(anc, row_number(), sep = "_"), anc)) |>
    ungroup() |>
    select(-maxval, -n) |>
    arrange(cname) |>
    select(cname, cluster, anc, everything())

  assign_cname_vec <- pull(assign_admix, cname, cluster)

  heatmap_names <- colnames(assign_admix_mat) |>
    (\(x) sprintf("%s (%s)", assign_cname_vec[x], x))()

  heatmap_mat <- assign_admix_mat
  colnames(heatmap_mat) <- heatmap_names

  return(list(assign = assign_admix,
              heatmap = heatmap_mat,
              assign_cname_vec = assign_cname_vec))
}

admix_labs <- assign_labels(tbl_admix)

assign_admix <- admix_labs$assign
heatmap_mat <- admix_labs$heatmap
assign_cname_vec <- admix_labs$assign_cname_vec
assign_super_vec <- pull(assign_admix, anc, cluster)
assign_cname_vec_i <- pull(assign_admix, cluster, cname)
superpops <- rownames(heatmap_mat)

rm(admix_labs, assign_labels)

# Assign individuals

collapse_superpop <- function(df, sp) {
  # Add overall proportion of each superpop, collapsing clusters
  get_clusters <- \(spop) names(assign_super_vec[assign_super_vec == spop])
  mutate(df, !!sp := rowSums(across(all_of(get_clusters(sp)))))
}

tbl_admix_collapsed <- tbl_admix
for (sp in superpops) {
  tbl_admix_collapsed <- collapse_superpop(tbl_admix_collapsed, sp)
}

tbl_admix_inf <- tbl_admix_collapsed |>
  rowwise(ID) |>
  mutate(maxval = max(c_across(all_of(cluster_cols))),
         matchval = which.max(c_across(all_of(cluster_cols))),
         max_spop_prop = max(c_across(all_of(superpops)))) |>
  ungroup() |>
  (\(.) mutate(.,
    maxclust = colnames(.)[max.col(select(., matches("^k\\d+$")))],
    "Maximum Cluster" = unname(assign_cname_vec[maxclust]),
    admixture_super_pop_max = map_chr(maxclust, \(x) assign_super_vec[[x]]),
    admixture_cluster_max = map_chr(maxclust, \(x) assign_cname_vec[[x]])))() |>
  arrange(spop, admixture_super_pop_max, matchval, -maxval) |>
  mutate(
    pop = forcats::fct_inorder(pop),
    spop = forcats::fct_inorder(spop),
    admixture_super_pop_max = factor(
      admixture_super_pop_max, levels = levels(spop))) |>
  arrange(matchval, -maxval) |>
  mutate(ID = forcats::fct_inorder(ID))

out_admix <- tbl_admix_inf |>
  select(-maxval, -matchval, -maxclust) |>
  select(any_of(c("FID", "IID", "ID")),
    all_of(superpops), matches("^k\\d+$"),
    everything()) |>
  filter(!is.na(pop) | partition == "sample")

# Filter samples

out_admix |>
  arrange(desc(partition), admixture_super_pop_max) |>
  fix_famfile() |>
  select(any_of(c("FID", "IID", "ID")), partition, admixture_cluster_max,
         admixture_super_pop_max, max_spop_prop, everything()) |>
  select(-`Maximum Cluster`) |>
  rename_with(~ paste0("k_", assign_cname_vec[.x]), matches("^k\\d+$")) |>
  write_tsv(out_anc)


```

And now we can visualize the global ancestry. 

```{r}
#| eval: false
#| label: Plot Admixture
#| code-summary: Plot Admixture
#| code-fold: TRUE

tbl_use <-  out_admix %>% 
  filter(partition == "sample") %>%
  pivot_longer(all_of(c('AFR', 'AMR', 'EAS', 'EUR', 'OCE', 'SAS')), names_to = "Cluster", values_to = "prop" ) |>
  mutate(spop = ifelse(genetic_region == "CSA", "SAS", genetic_region)) 

ggplot(tbl_use, aes(x = ID, y = prop, fill = Cluster)) +
    geom_bar(position = "fill", stat = "identity", width = 1) +
    scale_fill_manual(values = color_vector) + 
    theme_classic() +
    labs(x = "Individual", y = "Global Ancestry", color = "Cluster") +
    theme(
      axis.text.x = element_blank(),
      axis.ticks.x = element_blank(),
      axis.title.y = element_blank(),
      axis.title.x = element_blank(),
      panel.grid.major.x = element_blank(),
      strip.text.x = element_text(angle = 90)) + 
  facet_grid(~ admixture_super_pop_max, switch = "x",
                     scales = "free", space = "free")

ggsave()
```



