[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Introduction to Genetic Epidemiology",
    "section": "",
    "text": "Introduction\nThis is a Quarto book.\nTo learn more about Quarto books visit https://quarto.org/docs/books."
  },
  {
    "objectID": "scripts/schedule.html#week-1-0422---0426",
    "href": "scripts/schedule.html#week-1-0422---0426",
    "title": "Schedule",
    "section": "Week 1 04/22 - 04/26",
    "text": "Week 1 04/22 - 04/26\n\nMonday 04/22\nAlzheimer’s disease\nIn this mini-course, we will frequently reference Alzheimer’s disease to illustrate various genetic epidemiology methods. This session aims to introduce Alzheimer’s disease and explore significant findings related to its genetic architecture.\nReadings\n\nKnopman, D. S. et al. Alzheimer disease. Nat Rev Dis Primers 7, 33 (2021).\nAlzheimer’s Association. 2023 Alzheimer’s disease facts and figures. Alzheimer’s Dementia (2023).\nKornblith, E. et al. Association of Race and Ethnicity With Incidence of Dementia Among Older Adults. Jama 327, 1488–1495 (2022).\nAndrews, S. J. et al. The complex genetic architecture of Alzheimer’s disease: novel insights and future directions. eBioMedicine 90, 104511 (2023).\nAndrews, S. J., Fulton-Howard, B. & Goate, A. Interpretation of risk loci from genome-wide association studies of Alzheimer’s disease. Lancet Neurology 19, 326–335 (2020).\n\n\n\nWensday 04/24\nGenome-Wide Association Studies\nGenome-Wide Association Studies (GWAS) are foundational to various genetic analysis methodologies. In this session, we will delve into what a GWAS entails, the process of conducting one, and then engage in a hands-on exercise to carry out our own GWAS.\nCoursework\n\nSlides\nGWAS QC\nGWAS\nGWAS SS\n\nReadings\n\nUffelmann, E. et al. Genome-wide association studies. Nat Rev Methods Primers 1, 59 (2021).\nAbdellaoui, A., Yengo, L., Verweij, K. J. H. & Visscher, P. M. 15 years of GWAS discovery: Realizing the promise. Am J Hum Genetics (2023)\nMarees, A. T. et al. A tutorial on conducting genome‐wide association studies: Quality control and statistical analysis. Int J Method Psych 27, e1608 (2018).\nMacArthur, J. A. L. et al. Workshop proceedings: GWAS summary statistics standards and sharing. Cell Genom 1, 100004 (2021).\n\nTools\n\nPLINK1\nBCFTools2\nMungeSumStats3\n\n\n\nFriday 04/26\nGenetic Ancestry\nGenetic ancestry explores the lineage and heritage inferred from our DNA, providing insights into population history and individual heritage. This session will introduce the concepts and methodologies used in determining genetic ancestry, emphasizing their importance in genetic epidemiology research.\nCoursework\n\nSlides\nGenetic Ancestry\n\nReadings\n\nLewis, A. C. F. et al. Getting genetic ancestry right for science and society. Science 376, 250–252 (2022).\nNational Academies of Sciences, Engineering, and Medicine. 2023. Using Population Descriptors in Genetics and Genomics Research: A New Framework for an Evolving Field. Washington, DC: The National Academies Press.\n\nTools\n\nADMIXTURE4\nRFmix5"
  },
  {
    "objectID": "scripts/schedule.html#week-2-0429---0503",
    "href": "scripts/schedule.html#week-2-0429---0503",
    "title": "Schedule",
    "section": "Week 2 04/29 - 05/03",
    "text": "Week 2 04/29 - 05/03\n\nMonday 04/29\nHeritability & Genetic Correlations\nHeritability quantifies the proportion of phenotype variance attributable to genetic factors, whereas genetic correlations assess the extent of shared genetic architecture between traits. In this session, we will concentrate on the tools utilized to estimate these metrics from GWAS summary statistics.\nReadings\n\nRheenen, W. van, Peyrot, W. J., Schork, A. J., Lee, S. H. & Wray, N. R. Genetic correlations of polygenic disease traits: from theory to practice. Nat Rev Genetics 20, 567–581 (2019).\nBarry, C.-J. S. et al. How to estimate heritability: a guide for genetic epidemiologists. Int J Epidemiol (2022)\n\nCoursework\n\nSlides\n\nTools\n\nLDSC6\nHDL7\nGenomicSEM8\n\n\n\nWensday 05/01\nPolygenic Risk Scores I\nPolygenic risk scores (PRS) measure an invididueals total genetic liability for a trait. This session will cover the process of constructing a PRS and assessing its performance in predicting the trait.\nReadings\n\nChoi, S. W., Mak, T. S.-H. & O’Reilly, P. F. Tutorial: a guide to performing polygenic risk score analyses. Nat Protoc 15, 2759–2772 (2020).\nWand, H. et al. Improving reporting standards for polygenic scores in risk prediction studies. Nature 591, 211–219 (2021).\nLennon, N. J. et al. Selection, optimization and validation of ten chronic disease polygenic risk scores for clinical implementation in diverse US populations. Nat. Med. 1–8 (2024)\n\nCoursework\n\nSlides\n\nTools\n\nPRSice29\nPRSet10\n\n\n\nFriday 05/03\nPolygenic Risk Scores II\nThe accuracy of polygenic risk scores (PRS) diminishes as the genetic distance from the training population increases. This session will explore cross-ancestry PRS methods designed to enhance PRS accuracy across diverse populations.\nReadings\n\nKachuri, L. et al. Principles and methods for transferring polygenic risk scores across global populations. Nat. Rev. Genet. 1–18 (2023) doi:10.1038/s41576-023-00637-2.\nDing, Y. et al. Polygenic scoring accuracy varies across the genetic ancestry continuum. Nature 618, 774–781 (2023).\n\nCoursework\n\nSlides\n\nTools\n\nPRS-CSx11"
  },
  {
    "objectID": "scripts/schedule.html#week-3-0506---0510",
    "href": "scripts/schedule.html#week-3-0506---0510",
    "title": "Schedule",
    "section": "Week 3 05/06 - 05/10",
    "text": "Week 3 05/06 - 05/10\n\nMonday 05/06\nMendelian Randomization I\nMendelian Randomization (MR) is a method employed to identify causal risk factors for diseases. This session will cover the fundamentals of MR and demonstrate how to execute a two-sample MR analysis.\nReadings\n\nSanderson, E. et al. Mendelian randomization. Nat Rev Methods Primers 2, 6 (2022).\nDavies, N. M., Holmes, M. V. & Smith, G. D. Reading Mendelian randomisation studies: a guide, glossary, and checklist for clinicians. BMJ 362, k601 (2017).\nHemani, G. et al. The MR-Base platform supports systematic causal inference across the human phenome. Elife 7, e34408 (2018).\n\nTools\n\nTwoSampleMR12\n\n\n\nWensday 05/08\nMendelian Randomization II\nA crucial aspect of Mendelian Randomization (MR) studies is assessing whether the causal associations derived from MR analyses remain valid despite potential violations of MR’s underlying assumptions. This session will focus on diagnostic and sensitivity analyses in MR, along with guidance on effectively reporting MR findings.\nReadings\n\nSkrivankova, V. W. et al. Strengthening the Reporting of Observational Studies in Epidemiology Using Mendelian Randomization. JAMA 326, 1614–1621 (2021).\nSkrivankova, V. W. et al. Strengthening the reporting of observational studies in epidemiology using mendelian randomisation (STROBE-MR): explanation and elaboration. BMJ 375, n2233 (2021).\n\n\n\nFriday 05/10\nTrainee Presentations\nUpon concluding this mini-course, trainees will showcase the results of their analyses.\n\n\n\n\n1. Purcell S, Neale B, Todd-Brown K, et al. PLINK: A Tool Set for Whole-Genome Association and Population-Based Linkage Analyses. The American Journal of Human Genetics. 2007;81(3):559-575.\n\n\n2. Danecek P, Bonfield JK, Liddle J, et al. Twelve years of SAMtools and BCFtools. GigaScience. 2021;10(2):giab008.\n\n\n3. Murphy AE, Schilder BM, Skene NG. MungeSumstats: A Bioconductor package for the standardisation and quality control of many GWAS summary statistics. Bioinformatics. 2021;37(23):btab665-.\n\n\n4. Alexander DH, Novembre J, Lange K. Fast model-based estimation of ancestry in unrelated individuals. Genome Research. 2009;19(9):1655-1664.\n\n\n5. Maples BK, Gravel S, Kenny EE, Bustamante CD. RFMix: A Discriminative Modeling Approach for Rapid and Robust Local-Ancestry Inference. The American Journal of Human Genetics. 2013;93(2):278-288.\n\n\n6. Bulik-Sullivan B, Finucane HK, Anttila V, et al. An atlas of genetic correlations across human diseases and traits. Nature Genetics. 2015;47(11):1236-1241.\n\n\n7. Ning Z, Pawitan Y, Shen X. High-definition likelihood inference of genetic correlations across human complex traits. Nature Genetics. 2020;52(8):859-864.\n\n\n8. Grotzinger AD, Rhemtulla M, Vlaming R de, et al. Genomic structural equation modelling provides insights into the multivariate genetic architecture of complex traits. Nature human behaviour. 2019;3(5):513-525.\n\n\n9. Choi SW, O’Reilly PF. PRSice-2: Polygenic Risk Score software for biobank-scale data. GigaScience. 2019;8(7).\n\n\n10. Choi SW, García-González J, Ruan Y, et al. PRSet: Pathway-based polygenic risk score analyses and software. PLOS Genetics. 2023;19(2):e1010624.\n\n\n11. Ruan Y, Lin YF, Feng YCA, et al. Improving polygenic prediction in ancestrally diverse populations. Nature Genetics. 2022;54(5):573-580.\n\n\n12. Hemani G, Zheng J, Elsworth B, et al. The MR-Base platform supports systematic causal inference across the human phenome. eLife. 2018;7:e34408."
  },
  {
    "objectID": "scripts/conda.html#plink",
    "href": "scripts/conda.html#plink",
    "title": "Conda Env",
    "section": "PLINK",
    "text": "PLINK\nInstall plink\n#| eval: false\nsudo cp path/to/plink /usr/local/bin/`"
  },
  {
    "objectID": "scripts/habshd.html#phenotypes",
    "href": "scripts/habshd.html#phenotypes",
    "title": "HABS-HD",
    "section": "Phenotypes",
    "text": "Phenotypes\n\n\nImport Packges\nlibrary(tidyverse)\nsetwd('~/gitcode/IntroGeneticEpi/')\nSAVE_VISUALIZATIONS_PATH &lt;- \"results/figures\"\n\n\n\n\nImport Data\naa_v1_path = 'resources/HABSHD/v5/HD 1 African American 50+ Request 355.csv'\nma_v1_path = 'resources/HABSHD/v5/HD 1 Mexican American 50+ Request 355.csv'\nnhw_v1_path = 'resources/HABSHD/v5/HD 1 Non-Hispanic White 50+ Request 355.csv'\n\nhd_cols = spec(read_csv(nhw_v1_path, guess_max = 10000))\naa_v1.raw = read_csv(aa_v1_path, col_types = hd_cols,  na = c(\"\", \"NA\", \"9999\", \"-9999\", \"-8888\", \"-777777\", '-888888', '-999999')) %&gt;%\n  janitor::clean_names() \nma_v1.raw = read_csv(ma_v1_path, col_types = hd_cols,  na = c(\"\", \"NA\", \"9999\", \"-9999\", \"-8888\", \"-777777\", '-888888', '-999999')) %&gt;%\n  janitor::clean_names() \nnhw_v1.raw = read_csv(nhw_v1_path, col_types = hd_cols,  na = c(\"\", \"NA\", \"9999\", \"-9999\", \"-8888\", \"-777777\", '-888888', '-999999')) %&gt;%\n  janitor::clean_names() \n\nhabshd.raw &lt;- bind_rows(\n    aa_v1.raw, ma_v1.raw, nhw_v1.raw\n  ) %&gt;%\n  mutate(\n    id_race_white = as.factor(id_race_white),\n    id_race_black = as.factor(id_race_black),\n    id_race_indian_alaska = as.factor(id_race_indian_alaska),\n    id_race_asian = as.factor(id_race_asian),\n    id_race_japanese = as.factor(id_race_japanese),\n    id_race_korean = as.factor(id_race_korean),\n    id_race_vietnamese = as.factor(id_race_vietnamese),\n    id_race_native_hawaiian = as.factor(id_race_native_hawaiian),\n    id_race_guam_chamorro = as.factor(id_race_guam_chamorro),\n    id_race_samoan = as.factor(id_race_samoan),\n    id_race_other_pacific = as.factor(id_race_other_pacific),\n    id_race_other = as.factor(id_race_other),\n    id_hispanic = as.factor(id_hispanic),\n    id_hispanic_other = as.factor(id_hispanic_other), \n    race = case_when(\n      id_hispanic != 1 ~ \"Hispanic\", \n      id_race_white == 1 & id_hispanic != 2 ~ \"NHW\", \n      id_race_black == 1 ~ \"Black\",\n      TRUE ~ \"Other\")\n  )\n\n\n\n\nWrangle Data\nhabshd &lt;- habshd.raw %&gt;%\n  mutate(\n    abeta40 = ifelse(is.na(r3_qtx_plasma_abeta42), r5_qtx_plasma_abeta40, r3_qtx_plasma_abeta40), \n    abeta42 = ifelse(is.na(r3_qtx_plasma_abeta42), r5_qtx_plasma_abeta42, r3_qtx_plasma_abeta42), \n    ptau181 = ifelse(is.na(r3_qtx_plasma_p_tau181), r5_qtx_plasma_p_tau181, r3_qtx_plasma_p_tau181), \n    total_tau = ifelse(is.na(r3_qtx_plasma_total_tau), r5_qtx_plasma_total_tau, r3_qtx_plasma_total_tau), \n    nfl = ifelse(is.na(r3_qtx_plasma_nf_l), r5_qtx_plasma_nf_l, r3_qtx_plasma_nf_l)\n  ) %&gt;%\n  select(med_id, age, id_gender, interview_language, adi_state_rank, race, \n         id_education, smoke_ever, cdx_cog, cdx_depression,cdx_hypertension, \n         cdx_diabetes, cdx_dyslipidemia, cdr_sum, \n         om_bp1_dia, om_bp1_sys,\n         om_height, om_weight, om_bmi, om_ab_circumference,\n         bw_chol_total, bw_ld_lchol, bw_hdl_chol, bw_hba1c, gds_total,\n         abeta40, abeta42, ptau181, total_tau, nfl,\n         apoe4_snp\n         )\n\nwrite_csv(habshd, \"work/habshd_pheno.csv\")\n\n\n\n\nVariable Descriptions\n#descriptive table\ndescription &lt;- c(\"Medical ID\",\"\",\"1 = Female &lt;br&gt; 0 = Male\",\n                 \"Language in which &lt;br&gt; interview was administered\", \n                 \"Area Deprivation Index\",'Black, Hispanic, NHW', \n                 \"Years of Education\",\"Ever Smoked&lt;br&gt; (1:Yes, 0:No)\",\n                \"Cognitive Disorder:&lt;br&gt; 0: Cognitively Unimpaired &lt;br&gt;1:Mild Cognitive   \n                 Impairment&lt;br&gt;2: Dementia\", \"Depression&lt;br&gt; (1:Yes, 0:No)\",\n                 \"Hypertension &lt;br&gt; (1:Yes,0:No)\", \"Diabetes &lt;br&gt; (1:Yes,0:No)\",\n                  \"High Cholesterol (1:Yes,0:No)\", \n                 \"Clinical Dementia Rating (CDR):&lt;br&gt; Sum of Boxes\", \n                 \"Diastolic BP\", \"Systolic BP\",  \"Height (in)\", \"Weight (lbs)\",\n                 \"BMI\", \"Abdominal circumference (in)\", \"Total Cholesterol\",\n                \"LDL Cholesterol&lt;br&gt; (bad)\",\"HDL Cholesterol&lt;br&gt; (good)\",\n                \"Hemoglobin\",\"Geriatric Depression Scale (GDS)\",\n                \"abeta40\",\"abeta42\",\"ptau181\", \"total_tau\",\"nfl\",\n                \"APOE Genotype\")\n                 \ntable_desc &lt;- data.frame(cbind(names(habshd), description))\ntable_desc %&gt;% kbl(caption = '', col.names = c(\"Variable\", \"Description\"),\n                   escape = FALSE) %&gt;% \n  kable_classic(full_width = FALSE, html_font = \"Ariel\") %&gt;% \n  kable_styling(font_size = 16, position = \"center\") %&gt;% \n  column_spec(1:2, border_left = F, border_right = F) %&gt;% \n  pack_rows(\"Demographics\",1,7) %&gt;% \n  pack_rows(\"Clinical\",8,25) %&gt;% \n  pack_rows(\"Imaging\",26,30) %&gt;% \n  pack_rows(\"Genomics\",31,31) \n\n\n\nDescriptive Table\n\n\n\n\n\n\n\nVariable\nDescription\n\n\nDemographics\n\n\n\nmed_id\nMedical ID number\nNot an MRN\n\n\nage\nAge (yrs)\n\n\nid_gender\n1:Female\n0: Male\n\n\ninterview_language\nLanguage in which interview was administered\n1:English 2:Spanish\n\n\nadi_state_rank\nArea Deprivation Index\nLevels: 1,2,..,10\n1: least disadvantaged 10: most disadvantaged\n\n\nrace\nBlack, NHW, Hispanic\n\n\nid_education\nYears of Education\n\n\nClinical\n\n\n\nsmoke_ever\nEver smoked? 0:No 1:Yes\n\n\ncdx_cog\nCognitive Disorder\n0: Cognitively Unimpaired\n1:Mild Cognitive Impairment\n2: Dementia\n\n\ncdx_depression\nDepression 0:No 1:Yes\n\n\ncdx_hypertension\nHypertension 0:No  1:Yes\n\n\ncdx_diabetes\nDiabetes 0:No  1:Yes\n\n\ncdx_dyslipidemia.\nHigh Cholesterol 0:No 1:Yes\n\n\ncdr_sum\nClinical Dementia Rating (CDR)\nSum of Boxes\n\n\ngds_total\nGeriatric Depression Scale (GDS) sum of GDS 1 to GDS 30\n\n\nom_bp1_dia\nDiastolic BP\n\n\nom_bp1_sys\nSystolic BP\n\n\nom_height\nHeight (in)\n\n\nom_weight\nWeight (lbs)\n\n\nom_bmi\nBody Mass Index (BMI)\n\n\nom_ab_circumference\nAbdominal Circumference (in)\n\n\nbw_chol_total\nTotal Cholesterol (mg/dL)\n\n\nbw_ld_lchol\nLDL Cholesterol (mg/dL) (bad)\n\n\nbw_hdl_chol\nHDL Cholesterol (mg/dL) (good)\n\n\nbw_hba1c\nHemoglobin A1C% of total Hgb\n\n\nBiomarkers\n\n\n\nabeta40\n\\(A\\beta_{40}\\)\n\n\nabeta42\n\\(A\\beta_{42}\\)\n\n\nptau181\nPhospho-Tau (pg/mL)\nAverage CV: 0.07065\nAvgerage LLOD: 0.016\nAverage HLOD:349\n\n\ntotal_tau\nTotal Tau\n\n\nnfl\nNeurofilament Light (pg/mL)\nAverage CV: 0.038\nAvgerage LLOD: 0.038\nAverage HLOD:1800\n\n\nGenetics \n\n\n\napoe4_snp\nAPOE Genotype\nE2E3, E2E4, E3E3, E3E4, E4E4\n\n\n\n\n\nDescriptive Statistics - tables\nhabshd[which(habshd$adi_state_rank==\"GQ\"),] &lt;- NA\nhabshd[which(habshd$adi_state_rank==\"PH\"),] &lt;- NA\nhabshd[which(habshd$adi_state_rank==\"Invalid Address\"),] &lt;- NA\nhabshd[which(habshd$smoke_ever==2),] &lt;- NA\nhabshd$adi_state_rank &lt;- as.integer(habshd$adi_state_rank)\n\ntheme_gtsummary_compact()\ndemographics_table &lt;- habshd %&gt;% select(age,id_gender,interview_language,\n                                          adi_state_rank, race, id_education) %&gt;% \n                      tbl_summary(., by = race,\n                            statistic = list(\n                                    all_continuous() ~ \"{mean}&lt;br&gt; ({sd})\",\n                                    all_categorical()~ \"{p}%\"),\n                             digits = all_continuous()~2,\n                            label = c(age~\"Age\", id_gender ~ \"Gender\", \n                                      interview_language ~ \"Interview Language\",\n                                      adi_state_rank~ \"ADI State Rank\",\n                                      id_education~\"Education\"),\n                            missing_text = \"(Missing)\") %&gt;%  \n                          modify_header(label = \"**Demographic &lt;br&gt; Variables**\",\n                          all_stat_cols() ~ \"**{level}**&lt;br&gt; N = {n}\") %&gt;% \n                    as_gt() %&gt;% \n                  tab_options(column_labels.border.top.color = \"black\",\n                              column_labels.border.bottom.color = \"black\",\n                              table_body.border.bottom.color = \"black\",\n                              table_body.hlines.color = \"white\",\n                              table.font.size = 12,\n                              container.width = 500, \n                              container.height =500) %&gt;% \n                  fmt_markdown(columns = everything())\n\ngtsave(demographics_table,filename = file.path(SAVE_VISUALIZATIONS_PATH, \"demographics_summary.png\"))\n\n#convert to factors\ncdx_cols &lt;- names(habshd %&gt;% select(starts_with(\"cdx_\")))\nhabshd[cdx_cols] &lt;-lapply(habshd[cdx_cols], factor)\n\nclinical_table1 &lt;- habshd %&gt;% select(smoke_ever,cdx_cog,cdx_depression,\n                                     cdx_hypertension,cdx_diabetes,\n                                     cdx_dyslipidemia,cdr_sum, om_bp1_dia,\n                                     race) %&gt;% \n                  tbl_summary(., by = race, \n                              statistic = list(\n                                    all_continuous() ~ \"{mean} ({sd})\",\n                                    all_categorical()~ \"{p}%\"),\n                              digits = all_continuous()~2,\n                              label = c(smoke_ever ~ \"Smoke \",\n                                      cdx_cog ~ \"Cognitive Disorder\",\n                                      cdx_depression ~ \"Depression\",\n                                      cdx_hypertension ~ \"Hypertension\",\n                                      cdx_diabetes ~ \"Diabetes\",\n                                      cdx_dyslipidemia ~ \"Displedemia\",\n                                      cdr_sum ~ \"CDR Total Score\", \n                                      om_bp1_dia ~ \"Diastolic BP\"),\n                missing_text = \"(Missing)\") %&gt;%  \n               modify_header(label = \"**Clinical Variables**\",\n                              all_stat_cols() ~ \"**{level}**&lt;br&gt; N = {n}\") %&gt;% \n              as_gt() %&gt;% \n              tab_options(\n                      column_labels.border.top.color = \"black\",\n                      column_labels.border.bottom.color = \"black\",\n                      table_body.border.bottom.color = \"black\",\n                      table_body.hlines.color = \"white\",\n                      table.font.size = 12,\n                      container.height = 700,\n                      container.width = 700) %&gt;% \n              fmt_markdown(columns = everything()) \n\ngtsave(clinical_table1,filename = file.path(SAVE_VISUALIZATIONS_PATH, \"clinical_table1.png\"))\n\nclinical_table2 &lt;- habshd %&gt;% select(om_bp1_sys,om_height,om_weight,\n                                     om_bmi,om_ab_circumference,bw_chol_total,\n                                     bw_ld_lchol,bw_hdl_chol,race,bw_hba1c,\n                                     gds_total,race) %&gt;% \n                   tbl_summary(., by = race, \n                              statistic = list(\n                                    all_continuous() ~ \"{mean} ({sd})\",\n                                    all_categorical()~ \"{p}%\"),\n                              digits = all_continuous()~2,\n                              label = c(om_bp1_sys~\"Systoliuc BP\",\n                                      om_height ~ \"Height (in)\", \n                                      om_weight~ \"Weight(lbs)\",\n                                      om_bmi ~\"BMI\",\n                                      om_ab_circumference~ \"Abdominal &lt;br&gt;\n                                      Circumference (in)\",\n                                      bw_chol_total ~ \"Total Cholesterol\",\n                                      bw_ld_lchol~ \"LDL &lt;br&gt; Cholesterol\", \n                                      bw_hdl_chol~ \"HDL &lt;br&gt; Cholesterol\",\n                                      bw_hba1c~ \"Hemoglobin\",\n                                      gds_total ~ \"GDS Total\"),\n                             missing_text = \"(Missing)\") %&gt;%  \n                 modify_header(label = \"**Clinical &lt;br&gt; Variables**\",\n                              all_stat_cols() ~ \"**{level}**&lt;br&gt; N = {n}\") %&gt;% \n                as_gt() %&gt;% \n                tab_options(\n                        column_labels.border.top.color = \"black\",\n                        column_labels.border.bottom.color = \"black\",\n                        table_body.border.bottom.color = \"black\",\n                        table_body.hlines.color = \"white\",\n                        table.font.size = 12,\n                        container.height = 700,\n                        container.width = 700) %&gt;% \n                fmt_markdown(columns = everything()) \ngtsave(clinical_table2,filename = file.path(SAVE_VISUALIZATIONS_PATH, \"clinical_table2.png\"))\n\nhabshd$apoe4_snp = as.factor(habshd$apoe4_snp)\nimaging_genetics_table &lt;- habshd %&gt;% select(abeta40, abeta42,ptau181, total_tau,\n                                            nfl, apoe4_snp,race) %&gt;% \n                          tbl_summary(., by = race,\n                                      statistic = list(\n                                            all_continuous() ~ \"{mean} ({sd})\",\n                                            all_categorical()~ \"{p}%\"),\n                                      digits = all_continuous()~2,\n                                      label = c(abeta40~\"AB40\",\n                                                abeta42~\"AB42\",\n                                                ptau181 ~ \"pTau\", \n                                                total_tau ~ \"Total Tau\",\n                                                nfl~ \"Plasma NFL\", \n                                                apoe4_snp ~ \"APOE4 SNP\"),\n                                     missing_text = \"(Missing)\") %&gt;%  \n                        modify_header(label = \"**Imaging & Genetic &lt;br&gt;\n                                      Variables**\",\n                                  all_stat_cols() ~ \"**{level}**&lt;br&gt; N = {n}\") %&gt;% \n                        as_gt() %&gt;% \n                        tab_options(\n                                column_labels.border.top.color = \"black\",\n                                column_labels.border.bottom.color = \"black\",\n                                table_body.border.bottom.color = \"black\",\n                                table_body.hlines.color = \"white\",\n                                table.font.size = 12, \n                                container.width = 700, \n                                container.height =700) %&gt;% \n                      fmt_markdown(columns = everything())\n\ngtsave(imaging_genetics_table,filename = file.path(SAVE_VISUALIZATIONS_PATH, \"imaging_genetic_table.png\"))"
  },
  {
    "objectID": "scripts/habshd.html#genotyping",
    "href": "scripts/habshd.html#genotyping",
    "title": "HABS-HD",
    "section": "Genotyping",
    "text": "Genotyping\nSamples in HABS-HD were genotyped on the Illumina GSA array. These files have undergone basic variant and sample QC and then imputed on using the TOPMed imputation server. I have then filtered the imputed files to only HapMap III SNPS to make\n\nHapMap III\nDownload the hapmap_3.3.hg38.vcf.gz file from the Broad’s google bucket\n\nbcftools view -i 'AF &gt; 0 && TYPE=\"snp\" && N_ALT=1' resources/genetic_epi/resources_broad_hg38_v0_hapmap_3.3.hg38.vcf | \\\nbcftools view -H &gt; work/hapmap3_snps.txt\n\n\nhm3.raw &lt;- read_table(\"work/hapmap3_snps.txt\", col_names = F)\n\nhm3 &lt;- hm3.raw %&gt;%\n  mutate(\n    cpra = glue::glue(\"{X1}:{X2}:{X4}:{X5}\"), \n    X1 = as.numeric(str_replace(X1, 'chr', ''))\n  ) %&gt;%\n  filter(!is.na(X1)) %&gt;%\n  rename(chr = X1, pos = X2, rsid = X3, ref = X4, alt = X5) %&gt;%\n  select(-X6)\n\nout &lt;- hm3 %&gt;% \n  distinct(cpra, .keep_all = T) %&gt;%\n  distinct(rsid, .keep_all = T) \n\nout %&gt;% \n  select(cpra) %&gt;%\n  write_tsv(., 'work/hm3_extract.txt', col_names = F) \n\nout %&gt;% \n  select(cpra, rsid) %&gt;%\n  write_tsv(., 'work/hm3_crpa_rsid.txt', col_names = F) \n\n\nplink \\\n  --bfile resources/HABSHD/genotypes/all \\\n  --keep-allele-order \\\n  --extract work/hm3_extract.txt \\\n  --make-bed \\\n  --out work/habshd_hm3\n\nplink \\\n  --bfile work/habshd_hm3 \\\n  --keep-allele-order \\\n  --update-name work/hm3_crpa_rsid.txt \\\n  --make-bed \\\n  --out work/habshd_rsid"
  },
  {
    "objectID": "scripts/summarystats.html#lipids",
    "href": "scripts/summarystats.html#lipids",
    "title": "Summary Statistics",
    "section": "Lipids",
    "text": "Lipids\n\nWiller et al 2013\nA GWAS of low-density lipoprotein (LDL) cholesterol, high-density lipoprotein (HDL) cholesterol, triglycerides and total cholesterol levels conducted in 188,577 individuals that identified 157 loci were associated with lipid levels.\nWiller, C. J. et al. Discovery and refinement of loci associated with lipid levels. Nat Genet 45, 1274–83 (2013).\nSummary statistics\n\nLDL Cholesterol\nHDL Cholesterol\nTriglycerides\nTotal cholesterol\n\n\n\nLDL Cholesterol Manhattan - Willer 2013\nldl_path = \"resources/genetic_epi/summary_statistics/Willer2013ldl.chrall.CPRA_b37.tsv.gz\"\nldl_ss &lt;- read_tsv(ldl_path, comment = \"##\", col_types = coltypes, \n                        col_select = c(DBSNP_ID, CHROM, POS, REF, ALT, AF, BETA, SE, Z, P, N, TRAIT))\n\n# Filter on p &lt; 0.5 to reduce compute\nWiller2013ldl.man &lt;- ggman(filter(ldl_ss, P &lt; 0.05 & P &gt; 1e-100), \n                           snp = \"DBSNP_ID\", bp = \"POS\", chrom = \"CHROM\", pvalue = \"P\", relative.positions = TRUE, \n                           title = \"LDL Cholesterol - Willer 2013\") + \n  theme_classic() \n\nggsave('results/figures/Willer2013ldl_ggman.png', plot = Willer2013ldl.man, units = 'in', width = 9, height = 4)\n\n# HM3 \nwiller_hm3 &lt;- ldl_ss %&gt;%\n  semi_join(hm3, by = c('DBSNP_ID' = 'SNP'))\n\nwrite_tsv(willer_hm3, 'work/summary_statistics/Willer2013ldl_hm3.tsv.gz')\n\n\n\n\n\nWiller2013ldl_ggman\n\n\n\n\nGraham et al. 2021\nA GWAS of low-density lipoprotein (LDL) cholesterol, high-density lipoprotein (HDL) cholesterol, triglycerides and total cholesterol levels conducted using a multi-ancestry, genome-wide genetic discovery meta-analysis of lipid levels in approximately 1.65 million individuals, including 350,000 of non-European ancestries that found 773 lipid-associated genomic regions that contained 1,765 distinct index variants that reached genome-wide significance for at least 1 ancestry group and lipid trait\nGraham, S. E. et al. The power of genetic diversity in genome-wide association studies of lipids. Nature 600, 675–679 (2021).\nSummary Statistics\n\nLDL Cholesterol (EUR)\nHDL Cholesterol (EUR)\n\n\n\nLDL Cholesterol Manhattan - Graham 2021\n# Manhattan Plot\nGraham_ldl_path = \"resources/genetic_epi/summary_statistics/Graham2021ldl.chrall.CPRA_b37.tsv.gz\"\nGraham_ldl_ss &lt;- read_tsv(Graham_ldl_path, comment = \"##\", col_types = coltypes, \n                        col_select = c(DBSNP_ID, CHROM, POS, REF, ALT, AF, BETA, SE, Z, P, N, TRAIT))\n\n# Filter on p &lt; 0.5 to reduce compute\nGraham2021ldl.man &lt;- ggman(filter(Graham_ldl_ss, P &lt; 0.05 & P &gt; 1e-100), \n                           snp = \"DBSNP_ID\", bp = \"POS\", chrom = \"CHROM\", pvalue = \"P\", relative.positions = TRUE, \n                           title = \"LDL Cholesterol - Graham 2021\") + \n  theme_classic() \n\nggsave('results/figures/Graham2021ldl_ggman.png', plot = Graham2021ldl.man, units = 'in', width = 9, height = 4)\n\n# HM3 \nGraham_hm3 &lt;- Graham_ldl_ss %&gt;%\n  semi_join(hm3, by = c('DBSNP_ID' = 'SNP'))\n\nwrite_tsv(Graham_hm3, 'work/summary_statistics/Graham2021ldl_hm3.tsv.gz')\n\n\n\n\n\nGraham2021ldl_ggman"
  },
  {
    "objectID": "scripts/summarystats.html#alzheimers-disease",
    "href": "scripts/summarystats.html#alzheimers-disease",
    "title": "Summary Statistics",
    "section": "Alzheimer’s disease",
    "text": "Alzheimer’s disease\n\nKunkle 2019\nA GWAS of Alzheimer’s disease conducted in 94,437 indivudles by the International Genomics Alzheiemr’s Project that identified 20 genome-wide signiﬁcant loci.\nKunkle, B. W. et al. Genetic meta-analysis of diagnosed Alzheimer’s disease identifies new risk loci and implicates Aβ, tau, immunity and lipid processing. Nat Genet 51, 414–430 (2019).\nSummary statistics\n\nLate-onset Alzheimer’s disease (LOAD)\n\n\n\nAD Manhattan Plot\nAD_path = \"resources/genetic_epi/summary_statistics/Kunkle2019load_stage123.chrall.CPRA_b37.tsv.gz\"\nAD_ss &lt;- read_tsv(AD_path, comment = \"##\",  col_types = coltypes, \n                       col_select = c(DBSNP_ID, CHROM, POS, REF, ALT, AF, BETA, SE, Z, P, N, TRAIT))\n\n# Filter on p &lt; 0.5 to reduce compute\nkunkle2019load.man &lt;- ggman(filter(AD_ss, P &lt; 0.05 & P &gt; 1e-100), \n                            snp = \"DBSNP_ID\", bp = \"POS\", chrom = \"CHROM\", pvalue = \"P\", relative.positions = TRUE, \n                           title = \"AD - Kunkle 2019\") + \n  theme_classic()\n\nggsave('results/figures/Kunkle2019load_ggman.png', plot = kunkle2019load.man, units = 'in', width = 9, height = 4)\n\n# HM3\nKunkle_hm3 &lt;- AD_ss %&gt;%\n  semi_join(hm3, by = c('DBSNP_ID' = 'SNP'))\n\nwrite_tsv(Kunkle_hm3, 'work/summary_statistics/Kunkle2019load_hm3.tsv.gz')\n\n\n\n\n\nKunkle2019load_ggman\n\n\n\n\nBellenguez 2022\nA GWAS of Alzheimer’s disease and related dementias conducted using 111,326 clinically diagnosed/‘proxy’ AD cases and 677,663 controls that identified 75 risk loci, of which 42 were novel.\nBellenguez, C. et al. New insights into the genetic etiology of Alzheimer’s disease and related dementias. Nat Genet 54, 412–436 (2022).\nSummary statistics\n\nAlzheimer’s disease and related dementias (ADRD)\n\n\n\nADRD Manhattan Plot\nADRD_path = \"resources/genetic_epi/summary_statistics/Bellenguez2022load.chrall.CPRA_b37.tsv.gz\"\nADRD_ss &lt;- read_tsv(ADRD_path, comment = \"##\",  col_types = coltypes, \n                       col_select = c(DBSNP_ID, CHROM, POS, REF, ALT, AF, BETA, SE, Z, P, N, TRAIT))\n\n# Filter on p &lt; 0.5 to reduce compute\nadard.man &lt;- ggman(filter(ADRD_ss, P &lt; 0.05 & P &gt; 1e-100), \n                   snp = \"DBSNP_ID\", bp = \"POS\", chrom = \"CHROM\", pvalue = \"P\", relative.positions = TRUE, \n                   title = \"ADRD - Bellenguez 2022\"\n                   ) + \n  theme_classic()\n\nggsave('results/figures/Bellenguez2022load_ggman.png', plot = adard.man, units = 'in', width = 9, height = 4)\n\n# HM3\nADRD_hm3 &lt;- ADRD_ss %&gt;%\n  semi_join(hm3, by = c('DBSNP_ID' = 'SNP'))\n\nwrite_tsv(ADRD_hm3, 'work/summary_statistics/Bellenguez2022load_hm3.tsv.gz')\n\n\n\n\n\nBellenguez2022load_ggman"
  },
  {
    "objectID": "scripts/summarystats.html#educational-attainment",
    "href": "scripts/summarystats.html#educational-attainment",
    "title": "Summary Statistics",
    "section": "Educational Attainment",
    "text": "Educational Attainment\n\nLee et al 2018\nA large-scale genetic association analysis of educational attainment in a sample of approximately 1.1 million individuals and identify 1,271 independent genome-wide-significant SNPs\nLee, J. J. et al. Gene discovery and polygenic prediction from a genome-wide association study of educational attainment in 1.1 million individuals. Nat Genet 50, 1112–1121 (2018).\nSummary statistics\n\nYears of Education\n\n\n\nEducation Manhattan Plot\neduc_path = \"resources/genetic_epi/summary_statistics/Lee2018educ.chrall.CPRA_b37.tsv.gz\"\neduc_ss &lt;- read_tsv(educ_path, comment = \"##\",  col_types = coltypes, \n                       col_select = c(DBSNP_ID, CHROM, POS, REF, ALT, AF, BETA, SE, Z, P, N, TRAIT))\n\n# Filter on p &lt; 0.5 to reduce compute\neduc.man &lt;- ggman(filter(educ_ss, P &lt; 0.05 & P &gt; 1e-100), \n                   snp = \"DBSNP_ID\", bp = \"POS\", chrom = \"CHROM\", pvalue = \"P\", relative.positions = TRUE, \n                   title = \"Education - Lee 2018\"\n                   ) + \n  theme_classic()\n\nggsave('results/figures/Lee2018educ_ggman.png', plot = educ.man, units = 'in', width = 9, height = 4)\n\n# HM3\neduc_hm3 &lt;- educ_ss %&gt;%\n  semi_join(hm3, by = c('DBSNP_ID' = 'SNP'))\n\nwrite_tsv(educ_hm3, 'work/summary_statistics/Lee2018educ_hm3.tsv.gz')\n\n\n\n\n\nLee2018educ_ggman"
  },
  {
    "objectID": "scripts/gwas_qc.html#snp-qc",
    "href": "scripts/gwas_qc.html#snp-qc",
    "title": "GWAS QC",
    "section": "SNP QC",
    "text": "SNP QC\nSNP level QC consists of removing markers with excessive missingness or low allele frequency. This QC increases the power to identify true associations with disease risk by removing suboptimal markers that can increase false positives.\n\nCall Rate & Allele frequency\n95% was used as the SNP call rate threshhold (usually ≥ 95% or higher), and 1% was used as the MAF threshold (usually ≥ 1% or higher). \nFiltering SNPs on MAF and call rate can be done in PLINK 1.9 by typing the following (or similar) at the shell prompt. This uses 95% and 1% for the call-rate and MAF, respectively:\n\n\nImport Packges\n# Generate frequency reports\nplink \\\n    --bfile work/habshd_rsid \\\n    --keep-allele-order \\\n    --freq \\\n    --out work/habshd_snpqc  \n\nplink \\\n    --bfile work/habshd_rsid \\\n    --keep-allele-order \\\n    --freqx \\\n    --out work/habshd_snpqc  \n\n# Filter on call rate and maf\nplink \\\n    --bfile work/habshd_rsid \\\n    --keep-allele-order \\\n    --geno 0.05 --maf 0.01 \\\n    --make-bed --out work/habshd_snpqc  \n\n\n\n## ==== SNP Level Filtering ====\n# ---- readin plink .frq ---- ##\nmessage(\"reading plink frq file\")\nfreq.raw &lt;- read_table('work/habshd_snpqc.frq', col_names = T,\n  col_types = cols(\n  CHR = col_double(),\n  SNP =col_character(),\n  A1 = col_character(),\n  A2 = col_character(),\n  MAF = col_double(),\n  NCHROBS = col_double()\n))\n\n# ---- readin plink .frqx ---- ##\nmessage(\"reading plink frqx file\")\nfreqx.raw &lt;- read_tsv('work/habshd_snpqc.frqx', col_names = T,\n  col_types = cols(\n  CHR = col_double(),\n  SNP = col_character(),\n  A1 = col_character(),\n  A2 = col_character(),\n  `C(HOM A1)` = col_double(),\n  `C(HET)` = col_double(),\n  `C(HOM A2)` = col_double(),\n  `C(HAP A1)` = col_double(),\n  `C(HAP A2)` = col_double(),\n  `C(MISSING)` = col_double()\n))\n\n# ---- SNP level statisitcs ----\nsnps &lt;- freq.raw %&gt;%\n  full_join(freqx.raw, by = c(\"CHR\", \"SNP\", \"A1\", \"A2\")) %&gt;%\n  rename(AA = `C(HOM A1)`, AB = `C(HET)`, BB = `C(HOM A2)`, missing = `C(MISSING)`) %&gt;%\n  mutate(Call.rate = 1 - (missing / c(AA + AB + BB + missing))) %&gt;%\n  mutate(Call = Call.rate &gt;= 1 - 0.05) %&gt;%\n  mutate(Call.maf = MAF &lt; 0.01) \n\nFigure @ref(fig:MAFxcallrate) shows the SNP call rate versus minor allele frequncy across all typed SNPs in the study. The dashed lines denote the MAF and call rate QC thresholds. xxx SNPs were removed due to low call rate and xxx SNPs were removed due to low minor allele frequency.\n\nMAFxcallrate.p &lt;- ggplot(data = snps, aes(x = MAF, y = Call.rate)) +\n  geom_point(alpha = 0.3, size = 0.5) +\n  geom_hline(yintercept = 1 - 0.05, linetype = 2, colour = 'red') +\n  geom_vline(xintercept = 0.01, linetype = 2, colour = 'red') +\n  scale_x_log10(breaks = scales::trans_breaks(\"log10\", function(x) round(10^x, 3))) +\n  labs(y = 'Proportion of called genotypes', x = 'Minor Allele Frequency (log)') +\n  theme_bw() + annotation_logticks()\n\nggsave('results/plots/MAFxcallrate.png', plot = MAFxcallrate.p, height = 4, width = 6, units = 'in')\n\n\n\nHardy Weinberg Equilibrium\nViolations of Hardy Weinberg Equilibrium can indicate either the presence of population substructure, or the occurence of genotyping error. It is common practice to assume that violoations are indicative of genotyping error and remove SNPs in which the HWE test statistic has a corresponding p-value of less then 1x10-6. A threshold of xxx is used here.\nFor case-control data, HWE is generally not tested in cases to not exclude real selection against a phenotype, so it is best to include case-control status in the PLINK files.\n\nFiltering SNPs on Hardy Weinberg Equilibrium for autosomes only can be done in PLINK by typing the following at the shell prompt:\n\nplink \\\n    --bfile work/habshd_snpqc  \\\n    --keep-allele-order \\\n    --autosome \\\n    --hardy \\\n    --hwe 0.000001 \\\n    --make-bed --out work/habshd_hwe\n\n\n# ---- readin plink .hwe ---- ##\nmessage(\"reading plink hwe file\")\nhwe.raw &lt;- read_table2('work/habshd_hwe.hwe', col_types = cols(\n  CHR = col_integer(),\n  SNP = col_character(),\n  TEST = col_character(),\n  A1 = col_character(),\n  A2 = col_character(),\n  GENO = col_character(),\n  `O(HET)` = col_double(),\n  `E(HET)` = col_double(),\n  P = col_double()\n))\n\nsnps &lt;- snps %&gt;%\n  full_join(hwe.raw, by = c(\"CHR\", \"SNP\", \"A1\", \"A2\")) %&gt;%\n  mutate(hwe = P &gt; 0.000001) %&gt;%\n  as_tibble()\n\nsuppressPackageStartupMessages(library(ggtern))\n\nhweplot &lt;- snps %&gt;%\n  filter(!is.na(P)) %&gt;%\n  mutate(alph = ifelse(hwe, 0.2, 0.8),\n         hwe = ifelse(hwe, \"Pass\", \"Fail\")) %&gt;%\n  ggtern::ggtern(aes(x = AA, y = AB, z = BB, colour = hwe, alpha = alph)) +\n   geom_point(size = 0.5)  +\n   scale_colour_manual(name= 'Hardy Weinberg \\n Equilibrium',\n                       values = c(Pass = \"#377EB8\", Fail = \"#E41A1C\")) +\n   scale_alpha_continuous(guide = \"none\", range = c(0.8, 0.2)) +\n   theme_bw() + theme(legend.position = 'bottom')\n\nhweplot\n\ndetach(\"package:ggtern\", unload=TRUE)\n\nggsave('results/plots/hweplot.png', plot = hweplot, height = 4, width = 6, units = 'in')"
  },
  {
    "objectID": "scripts/gwas_qc.html#sample-qc",
    "href": "scripts/gwas_qc.html#sample-qc",
    "title": "GWAS QC",
    "section": "Sample QC",
    "text": "Sample QC\n\nCall Rate\nA low genotyping call rate in a sample can be indicative of poor DNA sample quality, so samples with a call rate &lt; xxx% are excluded from further analysis. \nFiltering samples on a call rate of 95% can be done in PLINK by typing the following at the shell prompt:\n\nplink \\\n    --bfile work/habshd_hwe \\\n    --keep-allele-order \\\n    --mind 0.05 \\\n    --make-bed --out work/habshd_sampleQC\n\n\n\nSex Discordance\nSamples with discordance between self-reported and genetically predicted sex likely have errors in sample handling, such as sample swaps. Predicted sex can be determined by calculating X chromosome heterozygosity using an F test, because biological men have one X chromosome and women have two. An F value of ~0.99 indicates males, and an F value of ~0.03 indicates females. Furthermore, checking X chromosome heterozygosity may reveal sex chromosome anomalies (~0.28 in reported females; ~0.35 in males).\nSince sex discordance may be due to sample swaps or to incorrect phenotyping, sex discordant samples should generally be removed unless a swap can be reliably resolved.\nIdentification of individuals with discordent sex can be done in PLINK 1.9 by typing the following at the shell prompt, which will produce a list of individuals with discordent sex data.\n\nplink \\\n    --bfile resources/HABSHD/genotypes/HABLE_GSA_20230418a_FINAL  \\\n    --check-sex --out work/HABLE_GSA_20230418a\n\nplink \\\n    --bfile resources/HABSHD/genotypes/HABLE_GSA_20220602_FINAL  \\\n    --check-sex --out work/HABLE_GSA_20220602\n\nawk 'FNR==1 && NR==1 {print; next} FNR&gt;1 {print}' work/HABLE_GSA_20220602.sexcheck work/HABLE_GSA_20230418a.sexcheck &gt; work/habshd_sexcheck.txt\n\n\n## ---- Read in Data ----##\nsexcheck.raw &lt;- read_table('work/habshd_sexcheck.txt')\n\n##  recode sex varibles\nsexcheck &lt;- sexcheck.raw %&gt;%\n  mutate(PEDSEX = recode(PEDSEX, '2' = 'Female', '1' = 'Male'))\n\n##  Exclude samples with no sex inconsistencies\nsex_exclude.samples &lt;- sexcheck %&gt;%\n  filter(STATUS == 'PROBLEM') %&gt;%\n  mutate(PEDSEX = recode(PEDSEX, '2' = 'Female', '1' = 'Male'))\n\nThe following plot (Fig. @ref(fig:sexplot)) displays the X Chromosome heterozygosity for self reported sex, with samples with problems highlighted in red. Table @ref(tab:sextab) displays the individule records that should be excluded from further downstream analysis.\n\nsexcheck.p &lt;- ggplot(data = sexcheck, aes(x = as.factor(PEDSEX), y = F, colour = STATUS, shape = STATUS)) +\n  geom_jitter() +\n  scale_color_manual(values = c( \"#377EB8\", \"#E41A1C\")) +\n  theme_bw() + labs(x = 'Self reported sex', y = 'X CHR Heterozygocity (F)') + theme(legend.position=\"bottom\")\n\nggsave('results/plots/sexcheck.png', plot = sexcheck.p, height = 4, width = 6, units = 'in')\n\n\n\nPruning\nPruning is typically done to remove linkage disequilibrium (LD) between SNPs, which is often a necessary step in various genetic analyses to ensure the independence of markers and is necessary for estimating heterozygosity, realtedness, and population stratification.\n\nplink \\\n  --bfile work/habshd_sampleQC \\\n  --indep-pairwise 50 5 0.2 \\\n  --out work/indepSNP\n\n\n\nHeterozygosity check\nInsufficient heterozygosity can indicate inbreeding or other family substructures, while excessive heterozygosity may indicate poor sample quality.\nIndividuals with outlying heterozygosity rates can be identified in PLINK 1.9 by typing the following command at the shell prompt:\n\nplink \\\n    --bfile work/habshd_sampleQC  \\\n    --extract work/indepSNP.prune.in \\\n    --het --out work/habshd\n\nThis produces a file containing Method-of-moments F coefficient estimates, which can be used to calculate the observed heterozygosity rate in each individual. Analysis is performed using an LD pruned snplist.\nWe calculate a heterozygocity similarly using observed and expected counts from the PLINK output [(Observed - Expected)/N) and exclude samples that are ± 3 sd from the cohort mean. \n\n## ---- Read in Data ----##\nhet.raw &lt;- read_table('work/habshd.het')\n\n## caluclate heterozygosity\nhet &lt;- het.raw %&gt;%\n  rename(O = `O(HOM)`, E = `E(HOM)`, N = `N(NM)`) %&gt;%\n  mutate(Het = (N - O) / N)\n\n##  Calculate exclusion thresholds\nupper.het &lt;- mean(het$Het) + sd(het$Het)*3\nlower.het &lt;- mean(het$Het) - sd(het$Het)*3\n\n##  Exclusion of samples\nhet &lt;- het %&gt;%\n  mutate(exclude = ifelse(Het &gt;= upper.het | Het &lt;= lower.het, TRUE, FALSE))\n\nhet_exclude.samples &lt;- het %&gt;% filter(exclude == TRUE)\n\nFigure @ref(fig:plothet) displays the distrubution of heterozygosity in xxx. Samples with excessive (Het &gt; xxx) or deficient (Het &lt; xxx) heterozygosity are colored red. Table @ref(tab:het) displays samples that are to be excluded.\n\nheterozygosity.p &lt;- ggplot(het, aes(x = Het, fill = exclude)) + geom_histogram(binwidth = 0.001) +\n  geom_vline(xintercept = upper.het, colour = 'red', linetype = 2) +\n  geom_vline(xintercept = lower.het, colour = 'red', linetype = 2) +\n  theme_bw() + scale_fill_manual(values = c(\"#377EB8\", \"#E41A1C\")) +\n  theme(legend.position = 'bottom') +\n  labs(x = 'Heterozygosity')\n\nggsave('results/plots/heterozygosity.png', plot = heterozygosity.p, height = 4, width = 6, units = 'in')\n\n\n\nCryptic Relatedness\nPopulation based cohorts are often limited to unrelated individuals as associations statistics often assume independence across individuals. Closely related samples will share more of their genome and are likely to be more phenotypically similar than than two individuals chosen randomly from the population. A common measure of relatedness is identity by descent (IBD), where a kinship correlation coefficient (pi-hat) greater 0.1 suggests that samples maybe related or duplicates samples.\n\n# IBD relationship table\n# https://github.com/WheelerLab/GWAS_QC/blob/master/example_pipelines/QC%20Analysis%20-%20Cox%20Lab%20Projects.pdf\n\nrel_tab &lt;- tibble(relationship = c(\"unrelated\", \"identical-twins\",\n                                   \"parent-child\", \"full-siblings\",\n                                   \"half-siblings\", \"grandparent-grandchild\",\n                                   \"avuncular\", \"half-avuncular\",\n                                   \"first-cousin\", \"half-first-cousin\",\n                                   \"half-sibling-first-cousin\"),\n  pi_hat = c(0, 1, 0.5, 0.5, 0.25, 0.25, 0.25, 0.125, 0.125, 0.0625, 0.375),\n  z0 = c(1, 0, 0, 0.25, 0.5, 0.5, 0.5, 0.75, 0.75, 0.875, 0.375),\n  z1 = c(0, 0, 1, 0.5, 0.5, 0.5, 0.5, 0.25, 0.25, 0.125, 0.5),\n  z2 = c(0, 1, 0, 0.25, 0, 0, 0, 0, 0, 0, 0.125)\n)\n\ndup_relationships &lt;- c(\"grandparent-grandchild\", \"avuncular\", \"half-avuncular\")\nrel_tab_filt &lt;- rel_tab %&gt;%\n  filter(relationship %nin% dup_relationships) %&gt;%\n  mutate(relationship = ifelse(relationship == \"half-siblings\", \"2nd degree\",\n                               ifelse(relationship == \"first-cousin\",\n                                      \"3rd degree\", relationship)))\n\nIdentifying duplicated or related samples can be done in PLINK 1.9 by typing the following command at the shell prompt.\n\nplink \\\n    --bfile work/habshd_sampleQC \\\n    --extract work/indepSNP.prune.in \\\n    --genome --min 0.05 --out work/habshd.ibd\n\n\n# select samples with kinship cofficents &gt; 0.1875\n# https://link.springer.com/protocol/10.1007/978-1-60327-367-1_19\npi_hat_thres = 0.1875\n\n# Find closest match\nclosest &lt;- function(vals, ref) {\n  fc &lt;- Vectorize(function(x) {\n    ref[which.min(abs(ref - x))]\n  }) #finds closest\n  fc(vals)\n}\n\n# Iteratively Remove related samples\nremove_samples &lt;- function(ibdcoeff, fam, msg = \"closely related to\") {\n  fam_fi &lt;- fam %&gt;%\n    mutate(FI = paste0(FID, \"_-_-tempsep-_-_\", IID)) %&gt;%\n    mutate(status = ifelse(status &gt; 2, 0.5, status))\n\n  ibdcoeff %&lt;&gt;%\n    mutate(FI1 = paste0(FID1, \"_-_-tempsep-_-_\", IID1),\n           FI2 = paste0(FID2, \"_-_-tempsep-_-_\", IID2))\n  related_samples &lt;- NULL\n  excluded &lt;- c()\n  fam_table &lt;- tibble(FID = c(\"deleteme\"),\n                      IID = c(\"deleteme\"),\n                      Related = c(\"deleteme\"))\n  while (nrow(ibdcoeff) &gt; 0) {\n    test_tab &lt;- plyr:::count(c(ibdcoeff$FI1, ibdcoeff$FI2))\n    if (!(\"x\" %in% names(test_tab))) {\n      print(ibdcoeff)\n    }\n    sample.counts &lt;- plyr:::count(c(ibdcoeff$FI1, ibdcoeff$FI2)) %&gt;%\n      as_tibble %&gt;%\n      rename(FI = x) %&gt;%\n      mutate(FI = as.character(FI)) %&gt;%\n      inner_join(fam_fi, by = \"FI\") %&gt;%\n      arrange(desc(qc_failed), status, desc(freq))\n    rm.sample &lt;- sample.counts[[1, \"FI\"]]\n    id_ &lt;- str_split(rm.sample, \"_-_-tempsep-_-_\")[[1]]\n    fid &lt;- id_[1]\n    iid &lt;- id_[2]\n    remtxt &lt;- sprintf(\"%s %i other samples.\",\n                      msg,\n                      sample.counts[[1, \"freq\"]])\n    message(paste(\"Removing sample\", iid, remtxt))\n    ft &lt;- tibble(FID = fid, IID = iid, Related = remtxt)\n    fam_table &lt;- fam_table %&gt;%\n      bind_rows(ft)\n    ibdcoeff &lt;- ibdcoeff[ibdcoeff$FI1 != rm.sample &\n                           ibdcoeff$FI2 != rm.sample, ]\n    related_samples &lt;- c(as.character(rm.sample), related_samples)\n  }\n  return(\n    list(related_samples = related_samples,\n         fam_table = filter(fam_table, Related != \"deleteme\"),\n         exclude_samples = tibble(FI = as.character(related_samples)) %&gt;%\n           separate(FI, c(\"FID\", \"IID\"), sep = \"_-_-tempsep-_-_\")))\n}\n\n\n# Import data \nfam &lt;- \"work/habshd_sampleQC.fam\" %&gt;%\n  read_table(col_types = \"cc---i\", col_names = c(\"FID\", \"IID\", \"status\")) %&gt;%\n  mutate(qc_failed = FALSE)\n\nrelatedness.raw = read_table(\"work/habshd_ibd.genome\") \n\nibdcoeff &lt;- relatedness.raw %&gt;%\n  filter(PI_HAT &gt; pi_hat_thres) %&gt;%\n  mutate(\n    pi_hat = closest(PI_HAT, rel_tab_filt$pi_hat),\n    z0 = closest(Z0, rel_tab_filt$z0),\n    z1 = closest(Z1, rel_tab_filt$z1),\n    z2 = closest(Z2, rel_tab_filt$z2),\n  ) %&gt;%\n  left_join(rel_tab_filt) \n\nibdcoeff_unrelated &lt;- remove_samples(ibdcoeff, fam)\n\nThe following histogram (Fig. @ref(fig:kinplot)) shows the distribution of proportion of IBD sharing (pi-hat in PLINK; PropIBD in KING) between all pairs.\n\nggplot(relatedness.raw, aes(x = PI_HAT)) +\n  geom_histogram(binwidth = 0.01, fill = \"#377EB8\") +\n  scale_y_continuous(trans = 'log10', breaks = scales::trans_breaks(\"log10\", function(x) round(10^x, 3))) + \n  coord_cartesian(xlim = c(min(relatedness.raw$PI_HAT) - 0.05, 1)) +\n  annotation_logticks() + \n  theme_bw() + \n  labs(x = \"IBD Sharing (pi-hat in PLINK)\") +\n  geom_vline(xintercept = pi_hat_thres,\n             colour = \"red\", linetype = 2)\n\nggsave(\"results/plots/ibd.png\", width = 4, height = 4, units = 'in')\n\nThe following plot (Fig. @ref(fig:relplot)) shows the xxx by the proportion of loci where individuals share zero alleles (Z0), where the proportion of IBD sharing is greater than 0.05. In family based studies, pairs are colored by IBD relationship. Table @ref(tab:ibdfail) displays the individuals where the kinship coefficient was greater than xxx in population based studies OR how were duplicates in family based studies.\n\nggplot(ibdcoeff, aes(x = Z0, y = Z1, color = relationship)) + \n  geom_point() + \n  labs(x = 'P(IBD=0)', y = \"P(IBD=0)\") + \n  theme_bw()\n\nggsave(\"results/plots/relatedness.png\", width = 6, height = 4, units = 'in')\n\n\n\nPopulation Substructure\nAfter excluding population outliers from the dataset, population substructure will remain due to the presence of genetic diversity within apparently homogenous populations. Within a single ethnic population, even subtle degrees of population stratification can bias results due to differences in allele frequencies between subpopulations. Principal components based on the observed genotypes in the dataset of interest can be used to capture information on substructure and be included as covariates in downstream analysis.\nTo obtain the principal components for the sample dataset after population outliers have been removed, type the following PLINK 1.9 commands at the shell prompt to generate the principal component eigenvalue and eigenvector files.\n\nplink \\\n    --bfile work/habshd_sampleQC \\\n    --extract work/indepSNP.prune.in \\\n    --pca 10 \\\n    --out work/habshd\n\n\n# PCA file from plink\n\nzscore = function(x){(x - mean(x, na.rm = TRUE)) / sd(x, na.rm = TRUE)}\n\n# Read in eigenvectors and z-score transform\npca &lt;- read_delim('work/habshd.eigenvec', \n                  delim = \" \", col_names = c(\"FID\", \"IID\", paste0(\"PC\", 1:10)),\n                  col_types = cols(.default = \"d\", FID = \"c\", IID = \"d\")) %&gt;%\n         mutate_at(paste0(\"PC\", 1:10), zscore) %&gt;%\n  left_join(habshd %&gt;% select(med_id, race), by = c('IID' = \"med_id\"))\n\n# read in egienvalues\neigenval.raw &lt;- parse_number(read_lines('work/habshd.eigenval'))\n\neigenval &lt;- tibble(eigenval = eigenval.raw,\n                   PC = 1:length(eigenval.raw)) %&gt;%\n              mutate(PVE = round(eigenval / sum(eigenval), 3)) %&gt;%\n              select(PC, eigenval, PVE)\n\n\n\nScree Plot\nThe below scree plot (Fig. @ref(fig:ScreePlotStrat)) shows the amount of variation retained by each principal component (Left) and the cumualtive proportion of variance explained by each principal compoent (Right).\n\n#Include the number of PC for where the cumualtive PVE is 95%\nPC.inc &lt;-  findInterval(0.95, cumsum(eigenval$PVE)) + 1\n\n## ---- Plot scree plot of proportion of varaince explained by Principal components ---- ##\np1 &lt;- ggplot(data = eigenval, aes(x = PC, y = PVE, group = factor(1))) +\n  geom_point(colour = '#377EB8') + geom_path(colour = '#377EB8') +\n  scale_x_continuous(breaks = c(1:10)) + \n  labs(x = 'Principal Components') +\n  theme_bw() + coord_cartesian(ylim = c(0,1), default = T)\n\n\np2 &lt;- ggplot(data = eigenval, aes(x=PC, y=cumsum(PVE), group = factor(1))) +\n  geom_point(colour = '#377EB8') + geom_path(colour = '#377EB8') +\n  scale_x_continuous(breaks = c(1:10)) + \n  labs(x = 'Principal Components', y = 'cumulative PVE') +\n  theme_bw() + coord_cartesian(ylim = c(0,1), default = T) +\n  geom_hline(yintercept = 0.95, colour = '#E41A1C', linetype = 2)\n\np3 &lt;- gridExtra::grid.arrange(p1, p2, ncol = 2)\n\nggsave(\"results/plots/screeplot.png\", plot = p3, width = 9, height = 4, units = 'in')\n\n\n\nPopulation substructure\nThe following plots show the population structure of xxx based on the first two (Fig. @ref(fig:2PCstrat)) and three (Fig. @ref(fig:3PCstrat))) principal components compared with the reference populations from 1000 Genomes.\n\n##  Plot Superpopulations, PC1 + PC2\nggplot(pca, aes(x = PC2, y = PC1, color = race)) +\n  geom_point() +\n  scale_color_brewer(palette = \"Set1\") + \n  theme_bw() + theme(legend.position = 'right')\n\nggsave(\"results/plots/pca.png\", width = 6, height = 4, units = 'in')\n\n\n\nExclude Samples\n\nbind_rows(\n  sex_exclude.samples, \n  het_exclude.samples,\n  ibdcoeff_unrelated$exclude_samples %&gt;% mutate_at(c('FID', 'IID'), as.numeric)\n) %&gt;%\n  select(FID, IID) %&gt;%\n  distinct(FID, IID) %&gt;%\n  write_tsv('work/habshd.ExcludeSamples.tsv', col_names = F)\n\n\nplink \\\n    --bfile work/habshd_sampleQC \\\n    --keep-allele-order \\\n    --remove work/habshd.ExcludeSamples.tsv \\\n    --make-bed --out work/habshd_gwas"
  },
  {
    "objectID": "scripts/gwas.html#import",
    "href": "scripts/gwas.html#import",
    "title": "GWAS",
    "section": "Import",
    "text": "Import\n\n\nImport Packages\nlibrary(tidyverse)\n\n\n\n\nImport Data\nfam &lt;- read_table('work/habshd_gwas.fam', col_names = c('FID', 'IID'))\nhabshd &lt;- read_csv(\"work/habshd_pheno.csv\") %&gt;% distinct(med_id, .keep_all = T)\npc &lt;- pca &lt;- read_delim('work/habshd.eigenvec', \n                  delim = \" \", col_names = c(\"FID\", \"IID\", paste0(\"PC\", 1:10)),\n                  col_types = cols(.default = \"d\", FID = \"c\", IID = \"d\"))"
  },
  {
    "objectID": "scripts/gwas.html#phenotype-file",
    "href": "scripts/gwas.html#phenotype-file",
    "title": "GWAS",
    "section": "Phenotype File",
    "text": "Phenotype File\n\n\nPhenotype File\npheno &lt;- fam %&gt;%\n  left_join(select(habshd, med_id, cdr_sum), by = c('IID' = 'med_id')) \n\npheno %&gt;%\n  write_tsv('work/habshd_gwas.pheno', col_names = F)"
  },
  {
    "objectID": "scripts/gwas.html#covariate-file",
    "href": "scripts/gwas.html#covariate-file",
    "title": "GWAS",
    "section": "Covariate File",
    "text": "Covariate File\n\n\nCovariate File\ncovar &lt;- fam %&gt;%\n  left_join(select(habshd, med_id, age, id_gender), by = c('IID' = 'med_id')) %&gt;%\n  left_join(select(pc, IID, PC1, PC2, PC3, PC4), by = 'IID') \n\ncovar %&gt;%\n  write_tsv('work/habshd_gwas.covar', col_names = F)"
  },
  {
    "objectID": "scripts/gwas.html#gwas",
    "href": "scripts/gwas.html#gwas",
    "title": "GWAS",
    "section": "GWAS",
    "text": "GWAS\n\n\nPLINK GWAS\nplink \\\n  --bfile work/habshd_gwas \\\n  --pheno work/habshd_gwas.pheno \\\n  --covar work/habshd_gwas.covar \\\n  --linear hide-covar \\\n  --out results/habshd_cdr_gwas"
  },
  {
    "objectID": "scripts/gwas.html#manhattan-plot",
    "href": "scripts/gwas.html#manhattan-plot",
    "title": "GWAS",
    "section": "Manhattan Plot",
    "text": "Manhattan Plot\n\n\nManhattan Plot\ngwas.raw &lt;- read_table('results/habshd_cdr_gwas.assoc.linear') %&gt;%\n  select(-X10)\n\ngwas.raw %&gt;% arrange(P)\n\ncdr_gwas.p &lt;- ggman::ggman(gwas.raw, snp = \"SNP\", bp = \"BP\", chrom = \"CHR\", pvalue = \"P\", relative.positions = TRUE) + \n  theme_classic()\n\nggsave(\"results/plots/cdr_gwas.png\", plot = cdr_gwas.p, width = 9, height = 4, units = 'in')"
  },
  {
    "objectID": "scripts/gwas_ss.html#mungesumstats",
    "href": "scripts/gwas_ss.html#mungesumstats",
    "title": "GWAS-SS",
    "section": "MungeSumstats",
    "text": "MungeSumstats\n\n\nLoad Packages\nlibrary(tidyverse)\n# library(MungeSumstats)\n\n\nThe MungeSumstats package is designed to facilitate the standardization of GWAS summary statistics."
  },
  {
    "objectID": "scripts/gwas_ss.html#ad-gwas",
    "href": "scripts/gwas_ss.html#ad-gwas",
    "title": "GWAS-SS",
    "section": "AD GWAS",
    "text": "AD GWAS\n\nKunkle 2019\nWe download the International Genomics of Alzheimer’s Project (IGAP) Alzheimer’s disease GWAS of Kunkle et al. Nat Genet, 2019. from the GWAS catalouge. These summary statistics correspond to the meta-analysis results obtained in stage 1 including genotyped and imputed data (11,480,632 variants, phase 1 integrated release 3, March 2012) of 21,982 Alzheimer’s disease cases and 41,944 cognitively normal controls.\nThe Summary statistics consists of the following information for each SNP and its association to Alzheimer’s disease based on meta-analysis in the publication mentioned below.\n\nChromosome: Chromosome of the SNP (Build 37, Assembly Hg19)\nPosition: Position of the SNP (Build 37, Assembly Hg19)\nMarkerName: SNP rsID or chromosome:position:I/D if rsID not available. I/D indicates indel or deletion respectively.\nEffect_allele: Reference allele (coded allele)\nNon_Effect_allele: Non reference allele (non coded allele)\nBeta: Overall estimated effect size for the effect allele\nSE: Overall standard error for effect size estimate\nPvalue: Meta-analysis Pvalue using regression coefficients (beta and standard error)\n\n\ncurl https://ftp.ebi.ac.uk/pub/databases/gwas/summary_statistics/GCST007001-GCST008000/GCST007511/Kunkle_etal_Stage1_results.txt &gt; resources/Kunkle_etal_Stage1_results.txt\n\n\n\nMunge Kunkle 2019\nkunkle.raw &lt;- read_table('resources/Kunkle_etal_Stage1_results.txt')\n\nkunkle &lt;- kunkle.raw %&gt;%\n  filter(nchar(Effect_allele) == 1 & nchar(Non_Effect_allele) == 1) %&gt;%\n  mutate(\n    Ncaas = 21982,\n    Nctrl = 41944,\n    N = 63926\n  )\n\n## b37\nkunkle_b37 &lt;- MungeSumstats::format_sumstats(path=kunkle,\n                                             ref_genome=\"GRCh37\",\n                                             dbSNP = 144,\n                                             return_data = TRUE\n                                             ) %&gt;%\n  as_tibble()\n\nwrite_tsv(kunkle_b37, 'work/summary_statistics/Kunkle2019load_b37.tsv.gz')\n\n## b38\nkunkle_b38 &lt;- MungeSumstats::format_sumstats(path=kunkle,\n                                             ref_genome=\"GRCh37\",\n                                             convert_ref_genome=\"GRCh38\",\n                                             dbSNP = 144,\n                                             return_data = TRUE\n                                             ) %&gt;%\n  as_tibble()\n\nwrite_tsv(kunkle_b38, 'work/summary_statistics/Kunkle2019load_b38.tsv.gz')\n\n\n\n\nBellenguez 2022\nWe download the IEuropean Alzheimer & Dementia Biobank (EADB) Alzheimer’s disease and related dementia (ADRD) GWAS of Bellenguez et al. Nat Genet, 2022 from the GWAS catalouge. These summary statistics correspond to the meta-analysis results obtained in stage 1, based on 39,106 clinically diagnosed AD cases, 46,828 proxy-ADD cases, 401,577 controls and 21,101,114 variants that passed quality control\nThe Summary statistics consists of the following information for each SNP and its association to Alzheimer’s disease based on meta-analysis in the publication mentioned below.\n\nChromosome: Chromosome of the SNP (Build 37, Assembly Hg19)\nPosition: Position of the SNP (Build 37, Assembly Hg19)\nMarkerName: SNP rsID or chromosome:position:I/D if rsID not available. I/D indicates indel or deletion respectively.\nEffect_allele: Reference allele (coded allele)\nNon_Effect_allele: Non reference allele (non coded allele)\nBeta: Overall estimated effect size for the effect allele\nSE: Overall standard error for effect size estimate\nPvalue: Meta-analysis Pvalue using regression coefficients (beta and standard error)\n\nvariant_id: rsid p_value: P-value chromosome: Chromosome of the SNP base_pair_location: Position of the SNP (GRCh38) effect_allele: Effect allele other_allele: non-Effect allele effect_allele_frequency: Effect allele Frequency odds_ratio: Odds Ration ci_lower: Lower 95%CI of OR ci_upper: Upper 95%CI of OR beta: log odds ratio standard_error: : log odds ratio SE n_cases: Total number of cases included in the meta-analysis n_controls: Total number of controls included in the meta-analysis het_isq: I^2 statistic which measures heterogeneity on scale of 0-100% het_pvalue: P-value for heterogeneity statistic variant_alternate_id: Marker ID with format chromosome:position:reference_allele:alternate_allele\n\ncurl https://ftp.ebi.ac.uk/pub/databases/gwas/summary_statistics/GCST90027001-GCST90028000/GCST90027158/GCST90027158_buildGRCh38.tsv.gz &gt; resources/GCST90027158_buildGRCh38.tsv.gz\n\n\n\nLake et al 2023\nLeveraged published GWAS summary statistics from European, East Asian, and African American populations, and an additional GWAS from a Caribbean Hispanic population using previously reported genotype data to perform the largest multi-ancestry GWAS meta-analysis of Alzheimer’s disease and related dementias to date, totaling 54,233 cases, 46,828 proxy-ADD cases, and 543,127 controls.\nColumns in the file:\n\nCHR: Chromosome code\nBP: Base pair position (hg19)\nMarkerName: SNP identifier\nA1: Effect allele\nA2: Non-effect allele\nN: Number of valid studies for this SNP\nP: Fixed-effects meta-analysis p-value\nP(R): Random-effects meta-analysis p-value\nOR: Fixed-effects OR estimate\nOR(R): Random-effects OR estimate\nQ: p-value for Cochrane’s Q statistic\nI: I^2 heterogeneity index (0-100)\nF0: Individual study beta: Bellenguez et al\nF1: Individual study beta: Caribbean Hispanic\nF2: Individual study beta: FinngenR6\nF3: Individual study beta: Kunkle et al. 2021\n\nF4: Individual study beta: Shigemizu et al. 2021\n\n\ncurl https://personal.broadinstitute.org/ryank/CARD_2023_Bellenguez.onlyEuroProxies.noFEbefore.0.01.meta.locuszoom.tsv.gz &gt; resources/CARD_2023_Bellenguez.onlyEuroProxies.noFEbefore.0.01.meta.locuszoom.tsv.gz\n\n\nMAMA AD-GWAS\n\n\nAFR AD GWAS\n\n\nAMR AD GWAS\n\n\nEAS AD GWAS"
  },
  {
    "objectID": "scripts/ancestry.html#prinicpal-component-analysis",
    "href": "scripts/ancestry.html#prinicpal-component-analysis",
    "title": "Genetic Ancestry",
    "section": "Prinicpal Component Analysis",
    "text": "Prinicpal Component Analysis\n\nPLINK PCA\nPLINK enables us to conduct Principal Component Analysis (PCA) on genetic data. In this case, we have merged the HABS-HD dataset with the 1000 Genomes (1KG) dataset to initially derive principal components from the 1KG, which are then used to project the genetic data of the HABS-HD dataset onto. This will generate two files work/imputed_1kG_merged.eigenvec - the eigenvectors - and work/imputed_1kG_merged.eigenval the PCs.\nTo run the following PLINK command you will need the following files.\n\nresources/genetic_epi/imputed_1kG_merged.bim\nresources/genetic_epi/imputed_1kG_merged.bed\nresources/genetic_epi/imputed_1kG_merged_fixed.fam\nresources/genetic_epi/1kG_pops.txt\nresources/genetic_epi/1kG_pops_unique.txt\n\nYou can simplfy this by softlinking the Box genetic_epi directory into the resources directory of the IntroGeneticEpi git repository.\nln -s ~/Box-Box/AndrewsLab/data/genetic_epi ~/gitcode/IntroGeneticEpi/resources\n\nplink \\\n    --keep-allele-order \\\n    --bfile resources/genetic_epi/imputed_1kG_merged \\\n    --fam resources/genetic_epi/imputed_1kG_merged_fixed.fam \\\n    --pca 10 \\\n    --within resources/genetic_epi/1kG_pops.txt \\\n    --pca-clusters resources/genetic_epi/1kG_pops_unique.txt \\\n    --out work/imputed_1kG_merged\n\n\n\nCluster Assignment\nTo categorize HABS-HD samples into the closest 1KG superpopulation, we calculate the geometric median for each cluster, assess the Euclidean distance from each sample to these medians, and assign samples to the nearest cluster accordingly.\n\n\nImport Packges\n#!/usr/bin/env Rscript\n\nmessage(\"Loading packages\")\n\nsuppressPackageStartupMessages(library(dplyr))\nlibrary(readr)\nlibrary(magrittr)\nsuppressPackageStartupMessages(library(tidyr))\nlibrary(stringr)\nlibrary(tibble)\nsuppressPackageStartupMessages(library(purrr))\nlibrary(ggplot2)\n\n# Get geometric median\n## rdocumentation.org/packages/bigutilsr/versions/0.3.3/topics/geometric_median\n\ngeometric_median &lt;- function(u, tol = 1e-10, maxiter = 1000, by_grp = NULL) {\n  if (!is.null(by_grp))\n    return(do.call(\"rbind\", by(u, by_grp, geometric_median)))\n  u_old &lt;- colMeans(u)\n  for (k in seq_len(maxiter)) {\n    norm &lt;- sqrt(rowSums(sweep(u, 2, u_old, \"-\")^2))\n    u_new &lt;- colSums(sweep(u, 1, norm, \"/\")) / sum(1 / norm)\n    diff &lt;- max(abs(u_new - u_old))\n    if (diff &lt; tol)\n      break\n    u_old &lt;- u_new\n  }\n  if (k == maxiter)\n    warning(\"The maximum number of iterations has been reached.\")\n  u_new\n}\n\n# assign sample to cluster\n## https://www.biorxiv.org/content/10.1101/2020.10.06.328203v2.full\n## adomingues.github.io/2015/09/24/finding-closest-element-to-a-number-in-a-list\n\nfind_cluster &lt;- function(df, clusters) {\n  superpops &lt;- clusters$superpop\n  samp_pcs &lt;- select(df, starts_with(\"PC\"))\n  mat &lt;- bind_rows(clusters, samp_pcs) %&gt;% {suppressWarnings(dist(.))}\n  # mat\n  clus &lt;- which.min(as.matrix(mat)[6, 1:5])\n  dplyr::mutate(df, superpop_infered = superpops[clus])\n}\n\n\nYou will need to ensure the following files are in your resources and work directories.\n\n\nImport Data\nvec &lt;- 'work/imputed_1kG_merged.eigenvec'\nval &lt;- 'work/imputed_1kG_merged.eigenval'\nbase &lt;- 'resources/genetic_epi/1kG_pops.txt'\ntarget &lt;- 'work/habshd_sampleQC.fam'\nsample &lt;- 'HABS-HD'\npopulation &lt;- 'all'\npcs_out_path &lt;- 'work/habs_pca.tsv'\ntg_pops_file &lt;- 'resources/genetic_epi/tg_subpops.tsv'\n\n\n#load(\"output/ADGC/x_present_AA/ADC8-AA_exclude.pca.params.Rdata\")\n\nif (tolower(population) == \"all\") {\n  all_pops &lt;- T\n} else {\n  all_pops &lt;- F\n}\n\n##---- Read in Data ----##\nmessage(\"Reading data files\")\n\n# count columns and PCs\nn_eig &lt;- count_fields(vec, tokenizer_delim(delim = \" \"), n_max = 1) - 2\n\n# Generate colnames\npc_names &lt;- paste0(\"PC\", 1:n_eig)\nnames_col &lt;- c(\"FID\", \"IID\", pc_names)\n\n# Read in eigenvectors and z-score transform\npca_orig &lt;- read_delim(vec,\n                  delim = \" \", col_names = names_col,\n                  col_types = cols(.default = \"d\", FID = \"c\", IID = \"c\")) %&gt;%\n         mutate_at(pc_names, function(x) as.vector(scale(x)))\n\n# read in egienvalues\neigenval &lt;- val %&gt;%\n  read_lines %&gt;%\n  parse_number %&gt;%\n  tibble(eigenval = .,\n         PC = factor(pc_names, levels = pc_names)) %&gt;% #PC Names\n  mutate(PVE = round(eigenval / sum(eigenval), 3)) %&gt;% #PVE\n  select(PC, eigenval, PVE) #Reorder columns\n\n# population data file, usually from 1000 genomes and potentially with extra ref\nbase_pops_raw &lt;- read_table(base, col_types = cols(.default = \"c\"))\n\n# population data from target set\nfamcols &lt;- c(\"FID\", \"IID\", \"PID\", \"MID\", \"Sex\", \"Pheno\")\ntarget_pops_raw &lt;- read_table(target, col_names = famcols,\n  col_types = \"ccccii\")\n\nmessage(\"Processing data\")\n# ---- Data wrangling ---- #\n\n# Read in populations and superpops\ntg_pops &lt;- read_tsv(tg_pops_file, col_types = \"cccc\")\npopulations &lt;- tg_pops %&gt;% select(pop, spop) %&gt;% deframe %&gt;% as.list\nsuperpops &lt;- unlist(populations) %&gt;% unique()\n\n# Deal with invalid cohort names\n\nif (sample %in% names(populations)) {\n  sample &lt;- paste0(\"s_\", sample)\n}\n\nif (sample %in% populations) {\n  sample_s &lt;- paste0(\"s_\", sample)\n} else {\n  sample_s &lt;- sample\n}\n\n\n##  Munge population dataframes from 1000 genomes\nbase_pops &lt;- base_pops_raw %&gt;%\n  mutate(cohort = \"Reference\",\n         superpop = recode(.$Population, !!!populations))\n\n##  Munge target population dataframes\ntarget_pops &lt;- target_pops_raw %&gt;%\n  select(FID, IID) %&gt;%\n  mutate(Population = sample, superpop = sample_s,\n    cohort = sample_s)\n\n## Check this\nremove_tg &lt;- TRUE\nif (remove_tg) {\n  target_pops &lt;- target_pops %&gt;%\n    filter(!(IID %in% base_pops$IID & FID %in% base_pops$FID))\n}\n\n# fix improperly split FID_IID\npca_fidiid &lt;- pca_orig %&gt;%\n  unite(\"FIDIID\", FID, IID, sep = \"_\")\n\n\n##  Munge PCA, base pop and target pop\nboth_pops &lt;- target_pops %&gt;%\n  bind_rows(base_pops) %&gt;%\n  ##### FIX BAD FID_IID SPLIT #####\n  unite(\"FIDIID\", FID, IID, sep = \"_\", remove = F)\n\npca_corrected &lt;- pca_fidiid %&gt;%\n  left_join(both_pops, by = \"FIDIID\") %&gt;%\n  select(any_of(names(both_pops)), everything(), -FIDIID) %&gt;%\n  mutate(FID = str_remove(FID, \"^1000g___\"))\n\n## Colours for plots\npca_col &lt;- pca_corrected %&gt;%\n  count(superpop) %&gt;%\n  mutate(color = ifelse(superpop == sample_s, \"black\", NA)) %&gt;%\n  mutate(color = ifelse(superpop == \"AFR\", \"#E69F00\", color)) %&gt;%\n  mutate(color = ifelse(superpop == \"AMR\", \"#0072B2\", color)) %&gt;%\n  mutate(color = ifelse(superpop == \"EAS\", \"#009E73\", color)) %&gt;%\n  mutate(color = ifelse(superpop == \"EUR\", \"#CC79A7\", color)) %&gt;%\n  mutate(color = ifelse(superpop == \"NFE\", \"#CC79A7\", color)) %&gt;%\n  mutate(color = ifelse(superpop == \"FIN\", \"#960018\", color)) %&gt;%\n  mutate(color = ifelse(superpop == \"SAS\", \"#D55E00\", color)) %&gt;%\n  mutate(color = ifelse(superpop == \"MID\", \"#56B4E9\", color)) %&gt;%\n  mutate(color = ifelse(superpop == \"AMI\", \"#F0E442\", color)) %&gt;%\n  add_row(\n    superpop = c(\"Black\", \"Hispanic\", \"NHW\"), \n    n = 0, \n    color = c(\"#E69F00\", \"#0072B2\", \"#CC79A7\")\n  )\n\n\n# Pull out 1000 genomes samples\nkg &lt;- filter(pca_corrected, cohort == \"Reference\")\n\n# find geometric median of each PC for each cluster\nclusters &lt;-\n  select(kg, starts_with(\"PC\")) %&gt;%\n  geometric_median(by_grp = kg$superpop) %&gt;%\n  as_tibble(rownames = \"superpop\")\n\n# extract sample information and assign to cluster\npca &lt;- pca_corrected %&gt;%\n  group_split(IID) %&gt;%\n  map_df(find_cluster, clusters)\n\n# Export PCA \nwrite_tsv(pca, pcs_out_path)\n\n\n\n\nVisualization\nNow we can visualize the PCA to see how HABS-HD clusters with 1KG\n\n\nVisualize 1KG + HABS-HD\ncolor_vector &lt;- setNames(pca_col$color, pca_col$superpop)\n\n# PC1 x PC2\nga_pc1 &lt;- ggplot() +  \n  geom_point(data = filter(pca, cohort == 'Reference'), \n             aes(x = PC1, y = PC2, color = superpop), shape = 15, size = 2) + \n  geom_point(data = filter(pca, cohort == 'HABS-HD'), \n             aes(x = PC1, y = PC2, color = superpop), size = 0.75) + \n  scale_color_manual(values = color_vector) + \n  theme_bw()\n\n# PC3 x PC4\nga_pc3 &lt;- ggplot() +  \n  geom_point(data = filter(pca, cohort == 'Reference'), \n             aes(x = PC3, y = PC4, color = superpop), shape = 15, size = 2) + \n  geom_point(data = filter(pca, cohort == 'HABS-HD'), \n             aes(x = PC3, y = PC4, color = superpop), size = 0.75) + \n  scale_color_manual(values = color_vector) + \n  theme_bw()\n\nhabshd_ga.p &lt;- cowplot::plot_grid(\n  ga_pc1, ga_pc3\n)\n\nggsave(\"results/plots/habs_hd_ga.png\", plot = habshd_ga.p, units = \"in\", width = 9, height = 4)\n\n\nLets join with the phenotype data to compare ancestry and race\n\n\nVisualize HABS-HD\npca_pheno &lt;- pca %&gt;% \n  filter(cohort == \"HABS-HD\") %&gt;%\n  mutate(IID = as.numeric(IID)) %&gt;%\n  left_join(read_csv('work/habshd_pheno.csv'), by = c('IID' = 'med_id'))\n\n# PC1 x PC2\nhabshd_ga &lt;- ggplot(pca_pheno, aes(x = PC1, y = PC2, color = superpop_infered)) +  \n  geom_point() + \n  scale_color_manual(values = color_vector) + \n  theme_bw() + \n  labs(title = \"Genetic Ancestry\")\n\n# PC1 x PC2\nhabshd_race &lt;- ggplot(pca_pheno, aes(x = PC1, y = PC2, color = race)) +  \n  geom_point() + \n  scale_color_manual(values = color_vector) + \n  theme_bw() + \n  labs(title = \"Race\")\n\nhabs_hd_race_ga.p &lt;- cowplot::plot_grid(\n  habshd_ga, habshd_race\n)\n\n\nggsave(\"results/plots/habs_hd_race_ga.png\", plot = habs_hd_race_ga.p, units = \"in\", width = 9, height = 4)"
  },
  {
    "objectID": "scripts/ancestry.html#admixture",
    "href": "scripts/ancestry.html#admixture",
    "title": "Genetic Ancestry",
    "section": "ADMIXTURE",
    "text": "ADMIXTURE\n\nReference Processing\nTo prepare the gnomAD reference, we did the following:\n\nRemove samples without a population inference from gnomAD or without high_quality set to TRUE.\nMake a column (spop) by doing the following with the populations inferred by gnomAD:\n\nMerge “nfe” and “fin” into “EUR”\nMove oceanic subjects from “oth” to their own “OCE” category.\nCapitalize all other superpopulations.\n\nMake a column (spop_checked) where the original superpopulations match the inferred superpopulations:\n\nThe new spop column is used for inferred superpopulation.\nThe genetic_region column is used for original superpopulation.\n“CSA” in genetic_region is considered a match to “SAS” in spop. “SAS” is used in the new column.\nAll subjects where there is no match are set to “NA”\n\n\n\n\nADMIXTURE Procedure\nThe following steps are used to generate Global Ancestry Inference (GAI) estimates:\n\nProcess the reference label data as described above.\nObtain the intersection of the reference and target varients, then prune the reference with a 100kb window and R^2 of 0.1.\nRestrict sample genotypes to those present in the pruned reference, then merge with the reference samples. Check that the .bim files are identical.\nRun unsupervised ADMIXTURE with K = 12 on the reference dataset.\nRun ADMIXTURE projection on the merged reference and target samples.\nRead in the processed reference labels, ADMIXTURE cluster estimates (Q files), and PLINK .fam files.\nMerge the reference labels with the ADMIXTURE cluster estimates and extract the reference samples for labeling, excluding Middle Eastern reference samples.\nLabel the clusters by assigning to each cluster the superpopulation with the highest average proportion within that cluster. The checked superpopulation labels are used for this labeling process.\nUsing the cluster labels, calculate GAI proportions and maximum superpopulation for all samples.\nVisualize below.\n\nWe can execute ADMIXTURE using the code below; however, it requires approximately 24 hours of compute time. We have determined that K=12 is the optimal number of ancestral populations for 1KG + HGDP datasets. Our goal is to project the HABS-HD samples onto this reference dataset. This will produce .Q and .P file that contain the estimated ancestry fractions for each individual across the inferred populations and the allele frequencies for each population respectivly.\n\nadmixture -P -s 42 habshd_merged_gnomad-hgdp-1kg.hg38.bed 12 -j1\n\nLets visualize the global ancestry of the HABS-HD dataset. Make sure the following files are in your work directory.\n\nwork/gnomad-hgdp-1kg_pruned_habshd.hg38.fam\nwork/habshd_merged_gnomad-hgdp-1kg.hg38.12.Q\nwork/habshd_merged_gnomad-hgdp-1kg.hg38.fam\nwork/hgdp_1kg.popdata.tsv.gz\n\n\n\nADMIXTURE Packages\nsuppressPackageStartupMessages(library(dplyr))\nlibrary(readr)\nlibrary(tidyr)\nlibrary(purrr)\nlibrary(tibble)\nlibrary(stringr)\n\n\n\n\nImport ADMIXTURE\n## Input and output files\nin_fam_ref &lt;- 'work/gnomad-hgdp-1kg_pruned_habshd.hg38.fam'\nin_q_samp &lt;- 'work/habshd_merged_gnomad-hgdp-1kg.hg38.12.Q'\nin_fam_samp &lt;- 'work/habshd_merged_gnomad-hgdp-1kg.hg38.fam'\nin_pops &lt;- 'work/hgdp_1kg.popdata.tsv.gz'\nout_anc &lt;- 'work/habshd_genetic_ancestry.tsv'\n\n# Fam and popfiles\n## ======================================##\nmessage(\"Reading pop file \\n\")\npops &lt;- in_pops |&gt;\n  read_tsv(col_types = cols(.default = \"c\")) |&gt;\n  rename(ID = IID)\n\nmessage(\"Reading fam files \\n\")\nread_fam &lt;- function(in_fam) {\n  in_fam |&gt;\n    read_table(col_names = c(\"ID\"), col_types = \"-c----\") |&gt;\n    mutate(order = row_number())\n}\n\nfamfile_ref &lt;- read_fam(in_fam_ref) |&gt;\n  mutate(partition = \"reference\")\nfamfile_samp &lt;- read_fam(in_fam_samp) |&gt;\n  mutate(partition = \"sample\")\n\nfamfile &lt;- bind_rows(famfile_ref, famfile_samp)\n\n# Interpreting unsupervised admixture output #\n## ======================================##\nmessage(\"Reading unsupervised admixture output \\n\")\n\nread_q &lt;- function(in_q, fam) {\n  in_q |&gt;\n    read_table(col_names = FALSE, col_types = cols(.default = \"d\")) |&gt;\n    bind_cols(fam) |&gt;\n    rename_with(~ str_replace(.x, \"^X\", \"k\"))\n}\n\ntbl_admix_samp &lt;- read_q(in_q_samp, famfile_samp)\n\noverlap &lt;- intersect(famfile_ref$ID, tbl_admix_samp$ID)\nif (length(overlap) == nrow(famfile_ref)) {\n  tbl_admix &lt;- tbl_admix_samp |&gt;\n    left_join(pops, by = \"ID\") |&gt;\n    mutate(partition = ifelse(ID %in% famfile_ref$ID, \"reference\", partition))\n  tbl_admix_ref &lt;- tbl_admix |&gt;\n    filter(ID %in% famfile_ref$ID) |&gt;\n    mutate(FID = \"reference\")\n  tbl_admix_samp &lt;- tbl_admix |&gt;\n    filter(!(ID %in% tbl_admix_ref$ID))\n} else if (length(overlap) != 0) {\n  stop(\"Missing reference samples\")\n} else {\n  tbl_admix_ref &lt;- read_q(in_q_ref, famfile_ref)\n  tbl_admix_ref &lt;- tbl_admix_ref |&gt;\n    left_join(pops, by = \"ID\") |&gt;\n    mutate(FID = \"reference\")\n  tbl_admix &lt;- bind_rows(tbl_admix_ref, tbl_admix_samp)\n}\n\n# Determining cluster labels\n\ncluster_cols &lt;- names(tbl_admix)[str_detect(names(tbl_admix), \"^k\\\\d+$\")]\n\nassign_labels &lt;- function(tbl_admix) {\n  if (\"spop_checked\" %in% colnames(tbl_admix)) {\n    assign_admix_raw &lt;- tbl_admix |&gt;\n      select(any_of(c(\"FID\", \"IID\", \"ID\")),\n        spop = spop_checked, matches(\"^k\\\\d+$\")) |&gt;\n      filter(spop != \"MID\") |&gt; # remove middle eastern from assignment\n      group_by(spop) |&gt;\n      summarise(across(where(is.numeric), mean)) |&gt;\n      filter(!is.na(spop))\n  } else {\n    assign_admix_raw &lt;- tbl_admix |&gt;\n      group_by(spop) |&gt;\n      summarise(across(where(is.numeric), mean)) |&gt;\n      filter(!is.na(spop))\n  }\n\n  assign_admix_mat &lt;- assign_admix_raw |&gt;\n    column_to_rownames(var = \"spop\") |&gt;\n    as.matrix()\n\n  assign_admix &lt;- assign_admix_mat |&gt;\n    t() |&gt;\n    as.data.frame() |&gt;\n    (\\(.) mutate(., anc = colnames(.)[apply(., 1, which.max)]))() |&gt;\n    as_tibble(rownames = \"cluster\") |&gt;\n    rowwise() |&gt;\n    mutate(maxval = max(c_across(where(is.numeric)))) |&gt;\n    group_by(anc) |&gt;\n    arrange(-maxval) |&gt;\n    mutate(n = n(),\n           cname = ifelse(n &gt; 1, paste(anc, row_number(), sep = \"_\"), anc)) |&gt;\n    ungroup() |&gt;\n    select(-maxval, -n) |&gt;\n    arrange(cname) |&gt;\n    select(cname, cluster, anc, everything())\n\n  assign_cname_vec &lt;- pull(assign_admix, cname, cluster)\n\n  heatmap_names &lt;- colnames(assign_admix_mat) |&gt;\n    (\\(x) sprintf(\"%s (%s)\", assign_cname_vec[x], x))()\n\n  heatmap_mat &lt;- assign_admix_mat\n  colnames(heatmap_mat) &lt;- heatmap_names\n\n  return(list(assign = assign_admix,\n              heatmap = heatmap_mat,\n              assign_cname_vec = assign_cname_vec))\n}\n\nadmix_labs &lt;- assign_labels(tbl_admix)\n\nassign_admix &lt;- admix_labs$assign\nheatmap_mat &lt;- admix_labs$heatmap\nassign_cname_vec &lt;- admix_labs$assign_cname_vec\nassign_super_vec &lt;- pull(assign_admix, anc, cluster)\nassign_cname_vec_i &lt;- pull(assign_admix, cluster, cname)\nsuperpops &lt;- rownames(heatmap_mat)\n\nrm(admix_labs, assign_labels)\n\n# Assign individuals\n\ncollapse_superpop &lt;- function(df, sp) {\n  # Add overall proportion of each superpop, collapsing clusters\n  get_clusters &lt;- \\(spop) names(assign_super_vec[assign_super_vec == spop])\n  mutate(df, !!sp := rowSums(across(all_of(get_clusters(sp)))))\n}\n\ntbl_admix_collapsed &lt;- tbl_admix\nfor (sp in superpops) {\n  tbl_admix_collapsed &lt;- collapse_superpop(tbl_admix_collapsed, sp)\n}\n\ntbl_admix_inf &lt;- tbl_admix_collapsed |&gt;\n  rowwise(ID) |&gt;\n  mutate(maxval = max(c_across(all_of(cluster_cols))),\n         matchval = which.max(c_across(all_of(cluster_cols))),\n         max_spop_prop = max(c_across(all_of(superpops)))) |&gt;\n  ungroup() |&gt;\n  (\\(.) mutate(.,\n    maxclust = colnames(.)[max.col(select(., matches(\"^k\\\\d+$\")))],\n    \"Maximum Cluster\" = unname(assign_cname_vec[maxclust]),\n    admixture_super_pop_max = map_chr(maxclust, \\(x) assign_super_vec[[x]]),\n    admixture_cluster_max = map_chr(maxclust, \\(x) assign_cname_vec[[x]])))() |&gt;\n  arrange(spop, admixture_super_pop_max, matchval, -maxval) |&gt;\n  mutate(\n    pop = forcats::fct_inorder(pop),\n    spop = forcats::fct_inorder(spop),\n    admixture_super_pop_max = factor(\n      admixture_super_pop_max, levels = levels(spop))) |&gt;\n  arrange(matchval, -maxval) |&gt;\n  mutate(ID = forcats::fct_inorder(ID))\n\nout_admix &lt;- tbl_admix_inf |&gt;\n  select(-maxval, -matchval, -maxclust) |&gt;\n  select(any_of(c(\"FID\", \"IID\", \"ID\")),\n    all_of(superpops), matches(\"^k\\\\d+$\"),\n    everything()) |&gt;\n  filter(!is.na(pop) | partition == \"sample\")\n\n# Filter samples\n\nout_admix |&gt;\n  arrange(desc(partition), admixture_super_pop_max) |&gt;\n  select(any_of(c(\"FID\", \"IID\", \"ID\")), partition, admixture_cluster_max,\n         admixture_super_pop_max, max_spop_prop, everything()) |&gt;\n  select(-`Maximum Cluster`) |&gt;\n  rename_with(~ paste0(\"k_\", assign_cname_vec[.x]), matches(\"^k\\\\d+$\")) |&gt;\n  write_tsv(out_anc)\n\n\n\n\nVisualization\nAnd now we can visualize the global ancestry.\n\n\nPlot Admixture\ntbl_use &lt;-  out_admix %&gt;% \n  filter(partition == \"sample\") %&gt;%\n  pivot_longer(all_of(c('AFR', 'AMR', 'EAS', 'EUR', 'OCE', 'SAS')), names_to = \"Cluster\", values_to = \"prop\" ) |&gt;\n  mutate(spop = ifelse(genetic_region == \"CSA\", \"SAS\", genetic_region)) \n\ntbl_use &lt;-  out_admix %&gt;% \n  filter(partition == \"sample\") %&gt;%\n  pivot_longer(all_of(c('k1', 'k2', 'k3', 'k4', 'k5', 'k6', 'k7', 'k8', 'k9', 'k9', 'k10', 'k11', 'k12')), names_to = \"Cluster\", values_to = \"prop\" ) |&gt;\n  mutate(spop = ifelse(genetic_region == \"CSA\", \"SAS\", genetic_region)) \n\n\nadmixture.p &lt;- ggplot(tbl_use, aes(x = ID, y = prop, fill = Cluster)) +\n    geom_bar(position = \"fill\", stat = \"identity\", width = 1) +\n    # scale_fill_manual(values = color_vector) + \n    theme_classic() +\n    labs(x = \"Individual\", y = \"Global Ancestry\", color = \"Cluster\") +\n    theme(\n      axis.text.x = element_blank(),\n      axis.ticks.x = element_blank(),\n      axis.title.y = element_blank(),\n      axis.title.x = element_blank(),\n      panel.grid.major.x = element_blank(),\n      strip.text.x = element_text(angle = 90)) + \n  facet_grid(~ admixture_super_pop_max, switch = \"x\",\n                     scales = \"free\", space = \"free\")\n\nggsave('results/plots/habshd_admixture.png', plot = admixture.p, units = 'in', width = 9, height = 4)"
  },
  {
    "objectID": "scripts/genetic_corr.html#methods",
    "href": "scripts/genetic_corr.html#methods",
    "title": "Heritability & Genetic Correlations",
    "section": "Methods",
    "text": "Methods\n\nTools & Publications\nR, GenomicSEM, LDSC, HDL\n\nBulik-Sullivan, B. et al. An atlas of genetic correlations across human diseases and traits. Nat Genet 47, 1236–1241 (2015).\nNing, Z., Pawitan, Y. & Shen, X. High-definition likelihood inference of genetic correlations across human complex traits. Nat Genet 52, 859–864 (2020).\n\nGenetic correlation (rg) refers to the degree to which the genetic determinants of two traits overlap - the proportion of variance that two traits share due to genetic causes. A positive genetic correlation between two traits implies that the same genetic variants are influencing both traits in the same direction. Conversely, a negative genetic correlation implies that the genetic variants influencing one trait are having the opposite effect on the other trait.\nLDSC: Linkage disequilibrium score regression (LDSC) leverages linkage disequilibrium (LD), the non-random association of alleles at different loci, to estimate genetic correlations between two traits. This method operates on the premise that single nucleotide polymorphisms (SNPs) with a higher count of LD partners (thus having a higher LD score) are typically more associated with a trait due to polygenicity, a condition where numerous genetic variants each exert a minor effect.\nHDL: High-definition likelihood (HDL) provides genetic correlation estimates that have higher accuracy and precision compared to LDSC. HDL achives this by using a full likelihood-based method that leverages LD information across the whole genome, where as LDSC only use partial information."
  },
  {
    "objectID": "scripts/genetic_corr.html#munge",
    "href": "scripts/genetic_corr.html#munge",
    "title": "Heritability & Genetic Correlations",
    "section": "Munge",
    "text": "Munge\nHere we will be using LDSC and HDL implemented using GenomicSEM - make sure to have it installed.\nYou will need to make sure the following summary statistics are in resources/genetic_epi/summary_statistics/\n\nWiller2013ldl.chrall.CPRA_b37.tsv.gz\nGraham2021ldl.chrall.CPRA_b37.tsv.gz\nKunkle2019load_stage123.chrall.CPRA_b37.tsv.gz\nBellenguez2022load.chrall.CPRA_b37.tsv.gz\n\n\n\n\n\n\n\nWarning\n\n\n\nWith large GWAS summary statistic files your local machine may run out of memory. There are also HapMap3 filtered summary statistic files avaliable\n\nwork/summary_statistics/Willer2013ldl_hm3.tsv.gz\nwork/summary_statistics/Graham2021ldl_hm3.tsv.gz\nwork/summary_statistics/Kunkle2019load_hm3.tsv.gz\nwork/summary_statistics/Bellenguez2022load_hm3.tsv.gz\n\nYou may also need to apply GenomicSEM::munge to a single summary statistic file at a time\n\n\nAnd that the LD Reference Panels are available in resources/genetic_epi/ld_ref/\nFirst we need to munge the GWAS summary statistics so they are in the format required for LDSC.\n\n\nMunge GWAS SumStats\n## Summary statistics - full summary stats, may cause memory failure\n# Willer2013ldl = \"resources/genetic_epi/summary_statistics/Willer2013ldl.chrall.CPRA_b37.tsv.gz\"\n# Graham2021ldl = \"resources/genetic_epi/summary_statistics/Graham2021ldl.chrall.CPRA_b37.tsv.gz\"\n# KunkleAD = \"resources/genetic_epi/summary_statistics/Kunkle2019load_stage123.chrall.CPRA_b37.tsv.gz\"\n# BellenguezAD = \"resources/genetic_epi/summary_statistics/Bellenguez2022load.chrall.CPRA_b37.tsv.gz\"\n\n## Summary statistics - HapMap3 filtered SNPs\nWiller2013ldl = \"work/summary_statistics/Willer2013ldl_hm3.tsv.gz\"\nGraham2021ldl = \"work/summary_statistics/Graham2021ldl_hm3.tsv.gz\"\nKunkleAD = \"work/summary_statistics/Kunkle2019load_hm3.tsv.gz\"\nBellenguezAD = \"work/summary_statistics/Bellenguez2022load_hm3.tsv.gz\"\n\n## LD Structure \nld_path = \"resources/genetic_epi/ld_ref/eur_w_ld_chr/\"\n\n## HAPMAP3 SNPs\nhm3_path = \"resources/genetic_epi/ld_ref/w_hm3.snplist\"\n\n\nGenomicSEM::munge(\n  files = c(Willer2013ldl, Graham2021ldl, KunkleAD, BellenguezAD), \n  hm3 = hm3_path, \n  trait.names = c(\"Willer2013ldl\", \"Graham2021ldl\", \"KunkleAD\", \"BellenguezAD\"), \n  maf.filter = 0.05, \n  column.names = list(\n    SNP='DBSNP_ID', \n    MAF='AF', \n    A1='ALT',\n    A2='REF', \n    effect='BETA', \n    N = \"N\"\n  ), \n  overwrite=FALSE\n)"
  },
  {
    "objectID": "scripts/genetic_corr.html#ldsc",
    "href": "scripts/genetic_corr.html#ldsc",
    "title": "Heritability & Genetic Correlations",
    "section": "LDSC",
    "text": "LDSC\nWe can then apply LDSC to estimate h2 and pairwise rg. As we are using binary outcomes, we need to specify sample and population prevalence.\n\n\n\nTrait Name\nSample Prevalence\nPopulation Prevalence\n\n\n\n\nWiller2013ldl\nNA\nNA\n\n\nGraham2021ldl\nNA\nNA\n\n\nBellenguezAD\n0.18\n0.31\n\n\nKunkleAD\n0.37\n0.31\n\n\n\n\n\nLDSC\nldsc.covstruct &lt;- GenomicSEM::ldsc(\n     traits = c(\"Willer2013ldl.sumstats.gz\", \"Graham2021ldl.sumstats.gz\", \"BellenguezAD.sumstats.gz\", \"KunkleAD.sumstats.gz\"),\n     trait.names = c(\"Willer2013ldl\", \"Graham2021ldl\", \"BellenguezAD\", \"KunkleAD\"), \n     sample.prev = c(NA, NA, 0.18, 0.37),\n     population.prev = c(NA, NA, 0.31, 0.31),\n     ld = ld_path, \n     wld = ld_path,\n     stand = TRUE\n     )"
  },
  {
    "objectID": "scripts/genetic_corr.html#hdl",
    "href": "scripts/genetic_corr.html#hdl",
    "title": "Heritability & Genetic Correlations",
    "section": "HDL",
    "text": "HDL\nWe can then apply HDL to estimate h2 and pairwise rg.\n\n\nHDL\nhdl.covstruct &lt;- GenomicSEM::hdl(\n     traits = c(\"Willer2013ldl.sumstats.gz\", \"Graham2021ldl.sumstats.gz\", \"BellenguezAD.sumstats.gz\", \"KunkleAD.sumstats.gz\"),\n     trait.names = c(\"Willer2013ldl\", \"Graham2021ldl\", \"BellenguezAD\", \"KunkleAD\"), \n     sample.prev = c(NA, NA, 0.18, 0.37),\n     population.prev = c(NA, NA, 0.31, 0.31),\n     LD.path=\"resources/UKB_imputed_hapmap2_SVD_eigen99_extraction/\", \n     method = \"piecewise\"\n     )"
  },
  {
    "objectID": "scripts/prs.html",
    "href": "scripts/prs.html",
    "title": "Polygenic Risk Scores",
    "section": "",
    "text": "Polygenic risk scores (PRS) are statistical estimates that quantify an individual’s genetic susceptibility to a particular disease based on the sum of risk alleles they carry."
  },
  {
    "objectID": "scripts/prsice.html#estimate-ad-prs",
    "href": "scripts/prsice.html#estimate-ad-prs",
    "title": "PRSice-2",
    "section": "Estimate AD-PRS",
    "text": "Estimate AD-PRS\nHere we will estimate three Alzheimer’s disease PRS using different base GWAS.\n\nKunkle et al 2019. Clinicaly diagnosed AD\nBellenguez et al 2022. Alzheimer’s disease and related dementias\nLaket et al 2023. Multi-ancestry meta analysis (MAMA) of Alzheimer’s disease and related dementias\n\nWe are constructing the PRS across nine different P-value thresholds (5e-8, 1e-7, 1e-6, 1e-5, 1e-4, 0.001, 0.01, 0.1, 0.5, 1) and apply a clumping process with a window size of 250kb and an r2 &gt; 0.1.\n\n\n\n\n\n\nWarning\n\n\n\nIt is crucial to ensure that both the base and target datasets use the same human genome build. To achieve this, we have used MungeSummstats to liftover all summary statistics to build 38.\n\n\nTo run PRSice-2 we need the following files:\nBase GWAS summary statistics (b38) - work/summary_statistics/Kunkle2019load_b38.tsv.gz - work/summary_statistics/Bellenguez20202adrd_b38.tsv.gz - work/summary_statistics/Lake2023adrd_b38.tsv.gz\nTarget PLINK Files (HABS-HD b38) - PLINK Genotype files: work/habshd_gwas.bim, work/habshd_gwas.fam, and work/habshd_gwas.fam - PLINK Phenotype file: work/habshd_gwas.pheno - PLINK Covariate file: work/habshd_gwas.covar\nPRSice-2 will generate several output files:\n\n*all_scrore: PRS for each defined Pt\n*prsice: Summary statistics for Pt PRS\n*best: Best Pt PRS based on R2\n*summary: Sumary statistics for Best Pt PRS\n\n\nAD-PRS (Kunkle 2019)\n\nWhat is the best Pt?\nWhat is the R2 for best Pt?\n\n\n\nAD-PRS PRSice\nRscript bin/PRSice.R --dir . \\\n    --prsice bin/PRSice \\\n    --base work/summary_statistics/Kunkle2019load_b38.tsv.gz \\\n    --snp SNP \\\n    --chr CHR \\\n    --bp BP \\\n    --A1 A2 \\\n    --A2 A1 \\\n    --stat BETA \\\n    --pvalue P \\\n    --target work/habshd_gwas \\\n    --pheno work/habshd_gwas.pheno \\\n    --cov work/habshd_gwas.covar \\\n    --thread 1 \\\n    --clump-kb 250kb \\\n    --clump-p 1.000000 \\\n    --clump-r2 0.100000 \\\n    --bar-levels 5e-8,1e-7,1e-6,1e-5,1e-4,0.001,0.01,0.1,0.5,1 \\\n    --fastscore \\\n    --no-default \\\n    --binary-target F \\\n    --all-score \\\n    --out work/Kunkle\n\n\n\n\nADRD-PRS (Bellenguez 2022)\n\nWhat is the best Pt?\nWhat is the R2 for best Pt?\n\n\n\nADRD-PRS PRSice\nRscript bin/PRSice.R --dir . \\\n    --prsice bin/PRSice \\\n    --base work/summary_statistics/Bellenguez20202adrd_b38.tsv.gz \\\n    --snp SNP \\\n    --chr CHR \\\n    --bp BP \\\n    --A1 A2 \\\n    --A2 A1 \\\n    --stat BETA \\\n    --pvalue P \\\n    --target work/habshd_gwas \\\n    --pheno work/habshd_gwas.pheno \\\n    --cov work/habshd_gwas.covar \\\n    --thread 1 \\\n    --clump-kb 250kb \\\n    --clump-p 1.000000 \\\n    --clump-r2 0.100000 \\\n    --bar-levels 5e-8,1e-7,1e-6,1e-5,1e-4,0.001,0.01,0.1,0.5,1 \\\n    --fastscore \\\n    --no-default \\\n    --binary-target F \\\n    --all-score \\\n    --out work/Bellenguez\n\n\n\n\nMAMA-PRS (Lake 2023)\n\nWhat is the best Pt?\nWhat is the R2 for best Pt?\n\n\n\nMAMA-PRS PRSice\nRscript bin/PRSice.R --dir . \\\n    --prsice bin/PRSice \\\n    --base work/summary_statistics/Lake2023adrd_b38.tsv.gz \\\n    --snp SNP \\\n    --chr CHR \\\n    --bp BP \\\n    --A1 A2 \\\n    --A2 A1 \\\n    --stat BETA \\\n    --pvalue P \\\n    --target work/habshd_gwas \\\n    --pheno work/habshd_gwas.pheno \\\n    --cov work/habshd_gwas.covar \\\n    --thread 1 \\\n    --clump-kb 250kb \\\n    --clump-p 1.000000 \\\n    --clump-r2 0.100000 \\\n    --bar-levels 5e-8,1e-7,1e-6,1e-5,1e-4,0.001,0.01,0.1,0.5,1 \\\n    --fastscore \\\n    --no-default \\\n    --binary-target F \\\n    --all-score \\\n    --out work/Lake"
  },
  {
    "objectID": "scripts/prsice.html#habs-hd",
    "href": "scripts/prsice.html#habs-hd",
    "title": "PRSice-2",
    "section": "HABS-HD",
    "text": "HABS-HD\nWe will now evaluate the association each AD-PRS with the Clinical Dementia Rating Scale and cognitive impairment. We will need the following files:\n\nPhenotypes: work/habshd_pheno.csv\nGenetic Ancestry & PCs: work/habs_pca.tsv\nPRS: work/prsice/Kunkle.all_score, work/prsice/Bellenguez.all_score, or work/prsice/Lake.all_score\n\n\n\nImport Packages\nlibrary(tidyverse)\nlibrary(pROC)\n# library(janitor)\n# library(broom)\n# library(performance)\n\n\n\n\nImport and munge data\n# File paths\npheno_path = \"work/habshd_pheno.csv\"\npcs_path = 'work/habshd_pca.tsv'\nad_prs_path = 'work/prsice/Kunkle.all_score'\nadrd_prs_path = 'work/prsice/Bellenguez.all_score'\nmama_prs_path = 'work/prsice/Lake.all_score'\n\n## HABS-HD Phenotypes\nhabshd &lt;- read_csv(pheno_path) %&gt;% distinct(med_id, .keep_all = T)\n\n## Genetic Ancestry & PCs\npcs &lt;- read_tsv(pcs_path) %&gt;%\n  filter(superpop == \"HABS-HD\") %&gt;%\n  select(-Population, -cohort, -superpop, -FID) %&gt;%\n  mutate(IID = as.numeric(IID)) %&gt;%\n  rename(superpop = superpop_infered) %&gt;%\n  filter(superpop != 'EAS')\n\n## PRS  \nprs_ad &lt;- read_table(ad_prs_path) %&gt;%\n  janitor::clean_names() %&gt;%\n  select(-fid) %&gt;% \n  mutate_at(vars(starts_with(\"pt_\")), list(z = ~as.vector(scale(.)))) %&gt;%\n  magrittr::set_colnames(., paste0('ad_', colnames(.)))\nprs_adrd &lt;- read_table(adrd_prs_path) %&gt;%\n  janitor::clean_names() %&gt;%\n  select(-fid) %&gt;% \n  mutate_at(vars(starts_with(\"pt_\")), list(z = ~as.vector(scale(.)))) %&gt;%\n  magrittr::set_colnames(., paste0('adrd_', colnames(.)))\nprs_mama &lt;- read_table(mama_prs_path) %&gt;%\n  janitor::clean_names() %&gt;%\n  select(-fid) %&gt;% \n  mutate_at(vars(starts_with(\"pt_\")), list(z = ~as.vector(scale(.)))) %&gt;%\n  magrittr::set_colnames(., paste0('mama_', colnames(.)))\n\n\n## Merge datasets\ndat &lt;- habshd %&gt;%\n  left_join(pcs, by = c('med_id' = 'IID')) %&gt;%\n  left_join(prs_ad, by = c('med_id' = 'ad_iid')) %&gt;%\n  left_join(prs_adrd, by = c('med_id' = 'adrd_iid')) %&gt;%\n  left_join(prs_mama, by = c('med_id' = 'mama_iid')) %&gt;%\n  filter(!is.na(ad_pt_5e_08) & !is.na(superpop)) %&gt;% \n  mutate(\n    race = fct_relevel(race, \"NHW\"), \n    superpop = fct_relevel(superpop, \"EUR\"), \n    dx = fct_recode(as.factor(cdx_cog), 'ctrl' = '0', 'case' = '1', 'case' = '2'), \n    dx = fct_relevel(dx, 'ctrl'), \n    apoe = fct_recode(apoe4_snp, \n                      'e2+' = 'E2E2', 'e2+' = 'E2E3',  \n                      'e4+' = 'E3E4', 'e4+' = 'E2E4', 'e4+' = 'E4E4', \n                      'e3/e3' = 'E3E3'\n                      ), \n    apoe = fct_relevel(apoe, 'e3/e3')\n  ) \n\n\n\nPRS Distribution\n\nWhat is the distribution of the AD-PRS across cases and controls?\nWhat is the relationship between AD-PRS and CDR\n\n\n\nPRS\n## Violin Plots - DX\nggplot(dat, aes(x = dx, y = ad_pt_5e_08_z, fill = dx)) + \n  geom_violin() + \n  geom_boxplot(width = 0.2, outliers = FALSE, fill = 'white') +\n  theme_bw()\n\n## Density Plots - DX\nggplot(dat, aes(x = ad_pt_5e_08_z, fill = dx)) + \n  geom_density(alpha = 0.5) + \n  theme_bw()\n\n## Scatter plot - CDR\nggplot(dat, aes(x = cdr_sum, y = ad_pt_5e_08_z)) + \n  geom_point() + \n  geom_smooth(method = 'lm') + \n  theme_bw()\n\n## Violin Plots - super_pop\nggplot(dat, aes(x = superpop, y = ad_pt_5e_08_z, fill = superpop)) + \n  geom_violin() + \n  geom_boxplot(width = 0.2, outliers = FALSE, fill = 'white') +\n  theme_bw()\n\n\n\n\nPredictive ability\n\nWhat is the association of the AD-PRS with cognitive impairment\n\n\n\nOR\nreduced_mod &lt;- glm(dx ~ age + id_gender + PC1 + PC2 + PC3 + PC4, \n    data = dat, family = 'binomial')\n\nfull_mod &lt;- glm(dx ~ z_prs + age + id_gender + PC1 + PC2 + PC3 + PC4, \n    data = dat, family = 'binomial')\n\nbroom::tidy(full_mod, exponentiate = T, conf.int = T)\n\n\n\n\nPredictive accuracy\n\nWhat is the R2 of the reduced model containing only covariates (age, sex and PC1-4)?\nWhat is the R2 of the full model including the AD-PRS (age, sex and PC1-4)?\n\n\n\nR2\nreduced_r2 &lt;- performance::r2_nagelkerke(reduced_mod)\nfull_r2 &lt;- performance::r2_nagelkerke(full_mod)\n\ntribble(\n  ~reduced, ~full, ~diff,\n  reduced_r2, full_r2, full_r2 - reduced_r2\n) \n\n\n\n\nDiscrimination\n\nWhat is the AUC of the reduced model containing only covariates (age, sex and PC1-4)?\nWhat is the AUC of the full model including the AD-PRS (age, sex and PC1-4)?\n\n\n\nAUC\n# Predict probabilities\nprobabilities_full &lt;- predict(full_mod, type = \"response\")\nprobabilities_reduced &lt;- predict(full_mod, type = \"response\")\n\n# Calculate AUC\nroc_curve_full &lt;- roc(response = dat$dx, predictor = probabilities_full)\nroc_curve_reduced &lt;- roc(response = dat$dx, predictor = probabilities_reduced)\n\nauc(roc_curve_full)\nauc(roc_curve_reduced)\n\nggroc(roc_curve_full) + \n  geom_abline(slope = 1, intercept = 1, linetype = 2) + \n  theme_bw()\n\n\n\n\nCalibration\n\n\nCalibration\nprobs &lt;- dat %&gt;% \n  select(med_id, dx) %&gt;%\n  mutate(\n    predicted = probabilities_full\n  ) %&gt;%\n  mutate(prob_bin = cut(predicted, breaks = seq(0, 1, by = 0.1), include.lowest = TRUE))\n\ncal_plot_breaks(probs, dx, predicted)\n\ndat2$predicted_probs &lt;- predict(full_mod, type = \"response\")\n\ndat2 &lt;- probs  %&gt;%\n  group_by(prob_bin) %&gt;%\n  summarise(observed_mean = mean(dx),\n            # predicted_mean = mean(predicted),\n            .groups = 'drop')\n\n## \n\nglm(dx ~ z_prs + age + id_gender + id_education + PC1 + PC2 + PC3 + PC4, \n                data = dat %&gt;% filter(race == 'Hispanic'), family = 'binomial') %&gt;%\n  broom::tidy()\n\nlm(cdr_sum ~ z_prs + age + id_gender + PC1 + PC2 + PC3 + PC4, \n   data = dat %&gt;% filter(superpop == 'AFR')) %&gt;%\n  broom::tidy()"
  },
  {
    "objectID": "scripts/prscsx.html#estimate-cross-ancestry-ad-prs",
    "href": "scripts/prscsx.html#estimate-cross-ancestry-ad-prs",
    "title": "PRS-CSx",
    "section": "Estimate Cross-ancestry AD-PRS",
    "text": "Estimate Cross-ancestry AD-PRS\nWe constructed a Cross-ancestry AD-PRS using PRS-CSx-auto, using the ancestry-specific AD GWAS used by Lake et al 2023 in their Multi-ancestry Meta-Analysis. Due to the computational time, we used Snakemake workflow to run each chromsome separately.\n\nBellenguez et al 2022. Stage 1, EUR\nKunkle et al 2021. AFR\nShigemizu et al 2021. EAS\nLake et al 2023. AMR\n\n\n\nAD-PRS PRS-CSx\n## PRS-CSx - Scorefile\npython resources/PRScsx/PRScsx.py \\\n  --ref_dir=resources/PRScsx/ld_ref\n  --bim_prefix=work/habshd_hm3\n  --sst_file=['work/ad_eur_csx.txt', 'work/ad_afr_csx.txt', 'work/ad_eas_csx.txt', 'work/ad_amr_csx.txt']\n  --a=1\n  --b=0.5\n  --phi=None\n  --n_gwas=[625942, 7970, 8036, 2240]\n  --pop=['EUR', 'AFR', 'EAS', 'AMR']\n  --n_iter=4000\n  --n_burnin=2000\n  --thin=5\n  --out_dir=work/habshd\n  --out_name=habshd\n  --chrom=['1']\n  --meta=TRUE\n  --seed=None\n\n## PLINK to generate AD-PRS in HABS-HD   \nplink --bfile work/habshd_hm3 --score work/habshd/habshd_META_pst_eff_a1_b0.5_phiauto_chrAll.txt 2 4 6 sum\nmv plink.profile work/habshd/habshd_META_pst_eff_a1_b0.5_phiauto_chrAll_scores.txt\n  \n\n\nTwo AD-PRS were generated, one including APOE, and the other excluding the APOE region.\n\nwork/prscsx/habshd_META_pst_eff_a1_b0.5_phiauto_chrAll_noAPOE_scores.txt\nwork/prscsx/habshd_META_pst_eff_a1_b0.5_phiauto_chrAll_scores.txt"
  },
  {
    "objectID": "scripts/prscsx.html#habs-hd",
    "href": "scripts/prscsx.html#habs-hd",
    "title": "PRS-CSx",
    "section": "HABS-HD",
    "text": "HABS-HD\nWe will now evaluate the association each AD-PRS with the Clinical Dementia Rating Scale and cognitive impairment. We will need the following files:\n\nPhenotypes: work/habshd_pheno.csv\nGenetic Ancestry & PCs: work/habs_pca.tsv\nPRSice: work/prsice/Kunkle.all_score, work/prsice/Bellenguez.all_score, or work/prsice/Lake.all_score\nPRS-CSx: work/prscsx/habshd_META_pst_eff_a1_b0.5_phiauto_chrAll_noAPOE_scores.txt and work/prscsx/habshd_META_pst_eff_a1_b0.5_phiauto_chrAll_scores.txt\n\n\n\nImport Packages\nlibrary(tidyverse)\nlibrary(pROC)\n# library(janitor)\n# library(broom)\n# library(performance)\n\n\n\n\nImport and munge data\n# File paths\npheno_path = \"work/habshd_pheno.csv\"\npcs_path = 'work/habshd_pca.tsv'\nad_prs_path = 'work/prsice/Kunkle.all_score'\nadrd_prs_path = 'work/prsice/Bellenguez.all_score'\nmama_prs_path = 'work/prsice/Lake.all_score'\nprscsx_path = 'work/prscsx/habshd_META_pst_eff_a1_b0.5_phiauto_chrAll_scores.txt'\nprscsx_no_apoe_path = 'work/prscsx/habshd_META_pst_eff_a1_b0.5_phiauto_chrAll_noAPOE_scores.txt'\n\n## HABS-HD Phenotypes\nhabshd &lt;- read_csv(pheno_path) %&gt;% distinct(med_id, .keep_all = T)\n\n## Genetic Ancestry & PCs\npcs &lt;- read_tsv(pcs_path) %&gt;%\n  filter(superpop == \"HABS-HD\") %&gt;%\n  select(-Population, -cohort, -superpop, -FID) %&gt;%\n  mutate(IID = as.numeric(IID)) %&gt;%\n  rename(superpop = superpop_infered) %&gt;%\n  filter(superpop != 'EAS')\n\n## PRS  \nprs_ad &lt;- read_table(ad_prs_path) %&gt;%\n  janitor::clean_names() %&gt;%\n  select(-fid) %&gt;% \n  mutate_at(vars(starts_with(\"pt_\")), list(z = ~as.vector(scale(.)))) %&gt;%\n  magrittr::set_colnames(., paste0('ad_', colnames(.)))\nprs_adrd &lt;- read_table(adrd_prs_path) %&gt;%\n  janitor::clean_names() %&gt;%\n  select(-fid) %&gt;% \n  mutate_at(vars(starts_with(\"pt_\")), list(z = ~as.vector(scale(.)))) %&gt;%\n  magrittr::set_colnames(., paste0('adrd_', colnames(.)))\nprs_mama &lt;- read_table(mama_prs_path) %&gt;%\n  janitor::clean_names() %&gt;%\n  select(-fid) %&gt;% \n  mutate_at(vars(starts_with(\"pt_\")), list(z = ~as.vector(scale(.)))) %&gt;%\n  magrittr::set_colnames(., paste0('mama_', colnames(.)))\nprscsx &lt;- read_table(prscsx_path) %&gt;%\n  janitor::clean_names() %&gt;%\n  select(-fid, -cnt, -cnt2, -pheno) %&gt;%\n  mutate_at(vars(starts_with(\"scoresum\")), list(z = ~as.vector(scale(.)))) %&gt;%\n  rename(prscsx = scoresum, prscsx_z = z) \nprscsx_noapoe &lt;- read_table(prscsx_no_apoe_path) %&gt;%\n  janitor::clean_names() %&gt;%\n  select(-fid, -cnt, -cnt2, -pheno) %&gt;%\n  mutate_at(vars(starts_with(\"scoresum\")), list(z = ~as.vector(scale(.)))) %&gt;%\n  rename(prscsx_noapoe = scoresum, prscsx_noapoe_z = z) \n\n## Merge datasets\ndat &lt;- habshd %&gt;%\n  left_join(pcs, by = c('med_id' = 'IID')) %&gt;%\n  left_join(prs_ad, by = c('med_id' = 'ad_iid')) %&gt;%\n  left_join(prs_adrd, by = c('med_id' = 'adrd_iid')) %&gt;%\n  left_join(prs_mama, by = c('med_id' = 'mama_iid')) %&gt;%\n  left_join(prscsx, by = c('med_id' = 'iid')) %&gt;%\n  left_join(prscsx_noapoe, by = c('med_id' = 'iid')) %&gt;%\n  filter(!is.na(prscsx) & !is.na(superpop)) %&gt;% \n  mutate(\n    race = fct_relevel(race, \"NHW\"), \n    superpop = fct_relevel(superpop, \"EUR\"), \n    dx = fct_recode(as.factor(cdx_cog), 'ctrl' = '0', 'case' = '1', 'case' = '2'), \n    dx = fct_relevel(dx, 'ctrl'), \n    apoe = fct_recode(apoe4_snp, \n                      'e2+' = 'E2E2', 'e2+' = 'E2E3',  \n                      'e4+' = 'E3E4', 'e4+' = 'E2E4', 'e4+' = 'E4E4', \n                      'e3/e3' = 'E3E3'\n                      ), \n    apoe = fct_relevel(apoe, 'e3/e3')\n  ) \n\n\n\nPRS Distribution\n\nWhat is the distribution of the AD-PRS across cases and controls?\nWhat is the relationship between AD-PRS and CDR\n\n\n\nPRS\n## Violin Plots - DX\nggplot(dat, aes(x = dx, y = prscsx_z, fill = dx)) + \n  geom_violin() + \n  geom_boxplot(width = 0.2, outliers = FALSE, fill = 'white') +\n  theme_bw()\n\n## Density Plots - DX\nggplot(dat, aes(x = prscsx_z, fill = dx)) + \n  geom_density(alpha = 0.5) + \n  theme_bw()\n\n## Scatter plot - CDR\nggplot(dat, aes(x = cdr_sum, y = prscsx_z)) + \n  geom_point() + \n  geom_smooth(method = 'lm') + \n  theme_bw()\n\n## Violin Plots - super_pop\nggplot(dat, aes(x = superpop, y = prscsx_z, fill = superpop)) + \n  geom_violin() + \n  geom_boxplot(width = 0.2, outliers = FALSE, fill = 'white') +\n  theme_bw()\n\n## Violin Plots - DX\nggplot(dat, aes(x = dx, y = prscsx_z, fill = dx)) + \n  facet_wrap(vars(`superpop`)) + \n  geom_violin() + \n  geom_boxplot(width = 0.2, outliers = FALSE, fill = 'white') +\n  theme_bw()\n\n\n\n\nPRS All\npt_long &lt;- dat %&gt;% \n  select(med_id, superpop, dx, prscsx_z, prscsx_noapoe_z, starts_with(c(\"ad_\", \"adrd_\", \"mama_\"))) %&gt;%\n  select(med_id, superpop, dx, ends_with(\"_z\")) %&gt;%\n  pivot_longer(\n    cols = prscsx_z:mama_pt_1_z,\n    names_to = c('model'),\n    values_to = 'prs'\n  ) %&gt;%\n  separate(model, into = c(\"model\", \"pt\"), sep = \"_pt_\") %&gt;%\n  mutate(\n    pt = str_replace(pt, \"_z\", \"\"),\n    pt = ifelse(model == 'prscsx_z', 1, pt),\n    pt = ifelse(model == 'prscsx_noapoe_z', 1, pt),\n    pt = fct_relevel(pt, '5e_08', '1e_07', '1e_06', '1e_05', '0_0001', '0_001', '0_01', '0_1', '0_5', '1')\n  )\n\nad_ga.p &lt;- ggplot(pt_long %&gt;% filter(model == 'ad'), aes(x = prs, fill = superpop)) + \n  facet_wrap(vars(pt), ncol = 3) + \n  geom_density(alpha = 0.5) + \n  theme_bw() +\n  labs(\n    title = \"Kunkle 2019\", \n    x = 'AD-PRS'\n  ) + \n  theme(\n    text = element_text(size = 8),\n    panel.grid = element_blank(),\n    strip.background = element_blank(),\n    strip.text = element_text(face = \"bold\")\n  )\n\nggsave('results/figures/ad_ga_pt.png', plot = ad_ga.p + theme(legend.position = 'none'), \n       units = 'in', width = 3, height = 4)\n\n\nadrd_ga.p &lt;-ggplot(pt_long %&gt;% filter(model == 'adrd'), aes(x = prs, fill = superpop)) + \n  facet_wrap(vars(pt), ncol = 3) + \n  geom_density(alpha = 0.5) + \n  theme_bw() +\n  labs(\n    title = \"Bellenguez 2022\", \n    x = 'AD-PRS'\n  ) + \n  theme(\n    text = element_text(size = 8),\n    panel.grid = element_blank(),\n    strip.background = element_blank(),\n    strip.text = element_text(face = \"bold\")\n  )\n\nggsave('results/figures/adrd_ga_pt.png', plot = adrd_ga.p + theme(legend.position = 'none'), \n       units = 'in', width = 3, height = 4)\n\n\nmama_ga.p &lt;-ggplot(pt_long %&gt;% filter(model == 'mama'), aes(x = prs, fill = superpop)) + \n  facet_wrap(vars(pt), ncol = 3) + \n  geom_density(alpha = 0.5) + \n  theme_bw() +\n  labs(\n    title = \"Lake 2023\", \n    x = 'AD-PRS'\n  ) + \n  theme(\n    text = element_text(size = 8),\n    panel.grid = element_blank(),\n    strip.background = element_blank(),\n    strip.text = element_text(face = \"bold\")\n  )\n\n\nggsave('results/figures/mama_ga_pt.png', plot = mama_ga.p + theme(legend.position = 'none'), \n       units = 'in', width = 3, height = 4)\nggsave('results/figures/mama_ga_pt_legend.png', plot = mama_ga.p, \n       units = 'in', width = 3, height = 4)\n\n\nprscsx_ga.p &lt;-ggplot(pt_long %&gt;% filter(model == 'prscsx_z'), aes(x = prs, fill = superpop)) + \n  geom_density(alpha = 0.5) + \n  theme_bw() +\n  labs(\n    title = \"PRS-CSx w/ APOE\", \n    x = 'AD-PRS'\n  ) + \n  theme(\n    text = element_text(size = 8),\n    panel.grid = element_blank(),\n    strip.background = element_blank(),\n    strip.text = element_text(face = \"bold\")\n  )\n\nggsave('results/figures/prscsx_ga.png', plot = prscsx_ga.p + theme(legend.position = 'none'), \n       units = 'in', width = 2, height = 2)\n\n\nprscsx_noapoe_ga.p &lt;-ggplot(pt_long %&gt;% filter(model == 'prscsx_noapoe_z'), aes(x = prs, fill = superpop)) + \n  geom_density(alpha = 0.5) + \n  theme_bw() +\n  labs(\n    title = \"PRS-CSx w/o APOE\", \n    x = 'AD-PRS'\n  ) + \n  theme(\n    text = element_text(size = 8),\n    panel.grid = element_blank(),\n    strip.background = element_blank(),\n    strip.text = element_text(face = \"bold\")\n  )\n\nggsave('results/figures/prscsx_noapoe_ga.png', plot = prscsx_ga.p + theme(legend.position = 'none'), \n       units = 'in', width = 2, height = 2)\n\n\n\n\nPredictive ability\n\nWhat is the association of the AD-PRS with cognitive impairment\n\n\n\nOR\nreduced_mod &lt;- glm(dx ~ age + id_gender + PC1 + PC2 + PC3 + PC4, \n    data = dat, family = 'binomial')\n\nfull_mod &lt;- glm(dx ~ prscsx_noapoe_z + apoe+ age + id_gender + PC1 + PC2 + PC3 + PC4, \n    data = dat, family = 'binomial')\n\nfull_mod &lt;- glm(dx ~ prscsx_noapoe_z + apoe + age + id_gender + PC1 + PC2 + PC3 + PC4, \n    data = dat %&gt;% filter(superpop == \"EUR\"), family = 'binomial') \n\nfull_mod &lt;- glm(dx ~ prscsx_z + age + id_gender + PC1 + PC2 + PC3 + PC4, \n    data = dat %&gt;% filter(superpop == \"EUR\"), family = 'binomial') \n\nbroom::tidy(full_mod, exponentiate = T, conf.int = T)\n\n\n\n\nPredictive accuracy\n\nWhat is the R2 of the reduced model containing only covariates (age, sex and PC1-4)?\nWhat is the R2 of the full model including the AD-PRS (age, sex and PC1-4)?\n\n\n\nR2\nreduced_r2 &lt;- performance::r2_nagelkerke(reduced_mod)\nfull_r2 &lt;- performance::r2_nagelkerke(full_mod)\n\ntribble(\n  ~reduced, ~full, ~diff,\n  reduced_r2, full_r2, full_r2 - reduced_r2\n) \n\n\n\n\nDiscrimination\n\nWhat is the AUC of the reduced model containing only covariates (age, sex and PC1-4)?\nWhat is the AUC of the full model including the AD-PRS (age, sex and PC1-4)?\n\n\n\nAUC\n# Predict probabilities\nprobabilities_full &lt;- predict(full_mod, type = \"response\")\nprobabilities_reduced &lt;- predict(full_mod, type = \"response\")\n\n# Calculate AUC\nroc_curve_full &lt;- roc(response = dat$dx, predictor = probabilities_full)\nroc_curve_reduced &lt;- roc(response = dat$dx, predictor = probabilities_reduced)\n\nauc(roc_curve_full)\nauc(roc_curve_reduced)\n\nggroc(roc_curve_full) + \n  geom_abline(slope = 1, intercept = 1, linetype = 2) + \n  theme_bw()\n\n\n\n\nCalibration\n\n\nCalibration\nprobs &lt;- dat %&gt;% \n  select(med_id, dx) %&gt;%\n  mutate(\n    predicted = probabilities_full\n  ) %&gt;%\n  mutate(prob_bin = cut(predicted, breaks = seq(0, 1, by = 0.1), include.lowest = TRUE))\n\ncal_plot_breaks(probs, dx, predicted)\n\ndat2$predicted_probs &lt;- predict(full_mod, type = \"response\")\n\ndat2 &lt;- probs  %&gt;%\n  group_by(prob_bin) %&gt;%\n  summarise(observed_mean = mean(dx),\n            # predicted_mean = mean(predicted),\n            .groups = 'drop')\n\n## \n\nglm(dx ~ z_prs + age + id_gender + id_education + PC1 + PC2 + PC3 + PC4, \n                data = dat %&gt;% filter(race == 'Hispanic'), family = 'binomial') %&gt;%\n  broom::tidy()\n\nlm(cdr_sum ~ z_prs + age + id_gender + PC1 + PC2 + PC3 + PC4, \n   data = dat %&gt;% filter(superpop == 'AFR')) %&gt;%\n  broom::tidy()"
  },
  {
    "objectID": "scripts/mr.html",
    "href": "scripts/mr.html",
    "title": "Mendelian Randomization",
    "section": "",
    "text": "TBD"
  },
  {
    "objectID": "scripts/references.html",
    "href": "scripts/references.html",
    "title": "References",
    "section": "",
    "text": "1. Purcell S, Neale B, Todd-Brown K, et al. PLINK: A Tool\nSet for Whole-Genome Association and Population-Based Linkage\nAnalyses. The American Journal of Human Genetics.\n2007;81(3):559-575.\n\n\n2. Danecek P, Bonfield JK, Liddle J, et al. Twelve years of SAMtools and BCFtools.\nGigaScience. 2021;10(2):giab008.\n\n\n3. Murphy AE, Schilder BM, Skene NG. MungeSumstats: A Bioconductor package for the\nstandardisation and quality control of many GWAS summary\nstatistics. Bioinformatics.\n2021;37(23):btab665-.\n\n\n4. Bulik-Sullivan B, Finucane HK, Anttila V, et\nal. An\natlas of genetic correlations across human diseases and\ntraits. Nature Genetics.\n2015;47(11):1236-1241.\n\n\n5. Ning\nZ, Pawitan Y, Shen X. High-definition likelihood inference of genetic\ncorrelations across human complex traits. Nature\nGenetics. 2020;52(8):859-864.\n\n\n6. Grotzinger AD, Rhemtulla M, Vlaming R de, et\nal. Genomic structural equation modelling provides insights\ninto the multivariate genetic architecture of complex traits.\nNature human behaviour. 2019;3(5):513-525.\n\n\n7. Choi\nSW, O’Reilly PF. PRSice-2: Polygenic Risk Score software for biobank-scale\ndata. GigaScience. 2019;8(7).\n\n\n8. Choi\nSW, García-González J, Ruan Y, et al. PRSet: Pathway-based polygenic risk score analyses and\nsoftware. PLOS Genetics. 2023;19(2):e1010624.\n\n\n9. Alexander DH, Novembre J, Lange K. Fast\nmodel-based estimation of ancestry in unrelated individuals.\nGenome Research. 2009;19(9):1655-1664.\n\n\n10. Maples BK, Gravel S, Kenny EE, Bustamante CD.\nRFMix: A Discriminative Modeling Approach for Rapid and\nRobust Local-Ancestry Inference. The American Journal of\nHuman Genetics. 2013;93(2):278-288.\n\n\n11. Ruan Y, Lin YF, Feng YCA, et al. Improving polygenic prediction in ancestrally diverse\npopulations. Nature Genetics.\n2022;54(5):573-580.\n\n\n12. Hemani G, Zheng J, Elsworth B, et al. The\nMR-Base platform supports systematic causal inference across the human\nphenome. eLife. 2018;7:e34408."
  },
  {
    "objectID": "scripts/acknowledgments.html",
    "href": "scripts/acknowledgments.html",
    "title": "Acknowledgments",
    "section": "",
    "text": "The code used to conduct the genotyping QC and ancestry assignments was developed by Brian Fulton-Howard, PhD for the QAIC workflow."
  }
]